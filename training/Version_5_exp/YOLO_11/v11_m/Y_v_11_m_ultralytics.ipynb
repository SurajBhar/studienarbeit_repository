{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ultralytics Framework for YOLO11 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of available GPUs: 4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Number of GPUs available\n",
    "num_gpus = torch.cuda.device_count()\n",
    "\n",
    "print(f\"Number of available GPUs: {num_gpus}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yolo11m Model Training on:\n",
    "- Carla_Labelling-v5 dataset\n",
    "- Train: 70% = 4485 Images\n",
    "- Validation: 20% = 1274 Images\n",
    "- Test: 10% = 641 Images\n",
    "\n",
    "- Hyperparameters are on automatic settings using Ultralytics package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ Python>=3.10 is required, but Python==3.9.19 is currently installed \n",
      "WARNING ⚠️ Python>=3.10 is required, but Python==3.9.19 is currently installed \n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load YOLOv10n model from scratch\n",
    "model = YOLO(\"yolo11m.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate the pretrained weights by running inference on an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "0: 448x640 4 horses, 80.7ms\n",
      "0: 448x640 4 horses, 80.7ms\n",
      "Speed: 20.8ms preprocess, 80.7ms inference, 617.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Speed: 20.8ms preprocess, 80.7ms inference, 617.4ms postprocess per image at shape (1, 3, 448, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error: no \"view\" rule for type \"image/png\" passed its test case\n",
      "       (for more information, add \"--debug=1\" on the command line)\n"
     ]
    }
   ],
   "source": [
    "# Run batched inference on a list of images\n",
    "results = model([\"/home/sur06423/project/1.jpg\"])  # return a list of Results objects\n",
    "\n",
    "# Process results list\n",
    "for result in results:\n",
    "    boxes = result.boxes  # Boxes object for bounding box outputs\n",
    "    masks = result.masks  # Masks object for segmentation masks outputs\n",
    "    keypoints = result.keypoints  # Keypoints object for pose outputs\n",
    "    probs = result.probs  # Probs object for classification outputs\n",
    "    obb = result.obb  # Oriented boxes object for OBB outputs\n",
    "    result.show()  # display to screen\n",
    "    result.save(filename=\"result.jpg\")  # save to disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model using the following guidelines:\n",
    "- Link for various arguments: https://docs.ultralytics.com/modes/train/#train-settings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1365, 2048, 3)\n"
     ]
    }
   ],
   "source": [
    "boxes = results[0]\n",
    "array = boxes.plot()\n",
    "print(array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ultralytics.engine.results.Results object with attributes:\n",
       "\n",
       "boxes: ultralytics.engine.results.Boxes object\n",
       "keypoints: None\n",
       "masks: None\n",
       "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
       "obb: None\n",
       "orig_img: array([[[101, 116, 135],\n",
       "        [ 90, 105, 124],\n",
       "        [ 90, 104, 123],\n",
       "        ...,\n",
       "        [ 45,  70,  60],\n",
       "        [ 56,  80,  70],\n",
       "        [ 36,  59,  51]],\n",
       "\n",
       "       [[ 91, 106, 125],\n",
       "        [ 93, 108, 127],\n",
       "        [ 99, 113, 132],\n",
       "        ...,\n",
       "        [ 48,  73,  63],\n",
       "        [ 52,  76,  66],\n",
       "        [ 37,  58,  50]],\n",
       "\n",
       "       [[ 81,  98, 117],\n",
       "        [ 92, 107, 126],\n",
       "        [ 94, 108, 127],\n",
       "        ...,\n",
       "        [ 46,  70,  60],\n",
       "        [ 55,  76,  67],\n",
       "        [ 52,  73,  65]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 86,  88,  88],\n",
       "        [ 86,  88,  88],\n",
       "        [ 87,  89,  89],\n",
       "        ...,\n",
       "        [ 50,  52,  52],\n",
       "        [ 52,  54,  54],\n",
       "        [ 58,  60,  60]],\n",
       "\n",
       "       [[ 88,  90,  90],\n",
       "        [ 93,  95,  95],\n",
       "        [ 90,  92,  92],\n",
       "        ...,\n",
       "        [ 43,  45,  45],\n",
       "        [ 38,  40,  40],\n",
       "        [ 49,  51,  51]],\n",
       "\n",
       "       [[ 83,  85,  85],\n",
       "        [ 87,  89,  89],\n",
       "        [ 78,  80,  80],\n",
       "        ...,\n",
       "        [ 52,  54,  54],\n",
       "        [ 44,  46,  46],\n",
       "        [ 50,  52,  52]]], dtype=uint8)\n",
       "orig_shape: (1365, 2048)\n",
       "path: '/home/sur06423/project/1.jpg'\n",
       "probs: None\n",
       "save_dir: 'runs/detect/predict'\n",
       "speed: {'preprocess': 20.753860473632812, 'inference': 80.74736595153809, 'postprocess': 617.4037456512451}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[101 116 135]\n",
      "  [ 90 105 124]\n",
      "  [ 90 104 123]\n",
      "  ...\n",
      "  [ 45  70  60]\n",
      "  [ 56  80  70]\n",
      "  [ 36  59  51]]\n",
      "\n",
      " [[ 91 106 125]\n",
      "  [ 93 108 127]\n",
      "  [ 99 113 132]\n",
      "  ...\n",
      "  [ 48  73  63]\n",
      "  [ 52  76  66]\n",
      "  [ 37  58  50]]\n",
      "\n",
      " [[ 81  98 117]\n",
      "  [ 92 107 126]\n",
      "  [ 94 108 127]\n",
      "  ...\n",
      "  [ 46  70  60]\n",
      "  [ 55  76  67]\n",
      "  [ 52  73  65]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 86  88  88]\n",
      "  [ 86  88  88]\n",
      "  [ 87  89  89]\n",
      "  ...\n",
      "  [ 50  52  52]\n",
      "  [ 52  54  54]\n",
      "  [ 58  60  60]]\n",
      "\n",
      " [[ 88  90  90]\n",
      "  [ 93  95  95]\n",
      "  [ 90  92  92]\n",
      "  ...\n",
      "  [ 43  45  45]\n",
      "  [ 38  40  40]\n",
      "  [ 49  51  51]]\n",
      "\n",
      " [[ 83  85  85]\n",
      "  [ 87  89  89]\n",
      "  [ 78  80  80]\n",
      "  ...\n",
      "  [ 52  54  54]\n",
      "  [ 44  46  46]\n",
      "  [ 50  52  52]]]\n"
     ]
    }
   ],
   "source": [
    "print(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: None\n",
      "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
      "obb: None\n",
      "orig_img: array([[[101, 116, 135],\n",
      "        [ 90, 105, 124],\n",
      "        [ 90, 104, 123],\n",
      "        ...,\n",
      "        [ 45,  70,  60],\n",
      "        [ 56,  80,  70],\n",
      "        [ 36,  59,  51]],\n",
      "\n",
      "       [[ 91, 106, 125],\n",
      "        [ 93, 108, 127],\n",
      "        [ 99, 113, 132],\n",
      "        ...,\n",
      "        [ 48,  73,  63],\n",
      "        [ 52,  76,  66],\n",
      "        [ 37,  58,  50]],\n",
      "\n",
      "       [[ 81,  98, 117],\n",
      "        [ 92, 107, 126],\n",
      "        [ 94, 108, 127],\n",
      "        ...,\n",
      "        [ 46,  70,  60],\n",
      "        [ 55,  76,  67],\n",
      "        [ 52,  73,  65]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 86,  88,  88],\n",
      "        [ 86,  88,  88],\n",
      "        [ 87,  89,  89],\n",
      "        ...,\n",
      "        [ 50,  52,  52],\n",
      "        [ 52,  54,  54],\n",
      "        [ 58,  60,  60]],\n",
      "\n",
      "       [[ 88,  90,  90],\n",
      "        [ 93,  95,  95],\n",
      "        [ 90,  92,  92],\n",
      "        ...,\n",
      "        [ 43,  45,  45],\n",
      "        [ 38,  40,  40],\n",
      "        [ 49,  51,  51]],\n",
      "\n",
      "       [[ 83,  85,  85],\n",
      "        [ 87,  89,  89],\n",
      "        [ 78,  80,  80],\n",
      "        ...,\n",
      "        [ 52,  54,  54],\n",
      "        [ 44,  46,  46],\n",
      "        [ 50,  52,  52]]], dtype=uint8)\n",
      "orig_shape: (1365, 2048)\n",
      "path: '/home/sur06423/project/1.jpg'\n",
      "probs: None\n",
      "save_dir: None\n",
      "speed: {'preprocess': 12.863397598266602, 'inference': 65.27900695800781, 'postprocess': 589.181661605835}\n"
     ]
    }
   ],
   "source": [
    "print(results[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "masks = results[0].masks\n",
    "print(masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/lib/xorg-nvidia-535.113.01/lib/x86_64-linux-gnu:/usr/lib/xorg/lib/x86_64-linux-gnu:/usr/lib/xorg-nvidia-525.116.04/lib/x86_64-linux-gnu:/home/sur06423/miniconda3/envs/yolov_env/lib/python3.9/site-packages/cv2/../../lib64:/usr/lib/xorg-nvidia-535.113.01/lib/x86_64-linux-gnu:/usr/lib/xorg/lib/x86_64-linux-gnu:/usr/lib/xorg-nvidia-525.116.04/lib/x86_64-linux-gnu:/usr/lib/xorg-nvidia-535.113.01/lib/x86_64-linux-gnu:/usr/lib/xorg/lib/x86_64-linux-gnu:/usr/lib/xorg-nvidia-525.116.04/lib/x86_64-linux-gnu:\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Set library paths\n",
    "os.environ['LD_LIBRARY_PATH'] = '/usr/lib/xorg-nvidia-525.116.04/lib/x86_64-linux-gnu:' + os.environ.get('LD_LIBRARY_PATH', '')\n",
    "os.environ['LD_LIBRARY_PATH'] = '/usr/lib/xorg/lib/x86_64-linux-gnu:' + os.environ['LD_LIBRARY_PATH']\n",
    "os.environ['LD_LIBRARY_PATH'] = '/usr/lib/xorg-nvidia-535.113.01/lib/x86_64-linux-gnu:' + os.environ['LD_LIBRARY_PATH']\n",
    "\n",
    "# Verify the update\n",
    "print(os.environ['LD_LIBRARY_PATH'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.14 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.13 🚀 Python-3.9.19 torch-2.4.1+cu121 CUDA:0 (NVIDIA RTX A6000, 48677MiB)\n",
      "                                                      CUDA:1 (NVIDIA RTX A6000, 48677MiB)\n",
      "                                                      CUDA:2 (NVIDIA RTX A6000, 48677MiB)\n",
      "                                                      CUDA:3 (NVIDIA RTX A6000, 48677MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolo11m.pt, data=/home/sur06423/project/Version_5_exp/Carla_Labeling-5/data.yaml, epochs=100, time=None, patience=10, batch=128, imgsz=640, save=True, save_period=1, cache=False, device=[0, 1, 2, 3], workers=6, project=/home/sur06423/project/Version_5_exp/YOLO_11/v11_m, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=True, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/home/sur06423/project/Version_5_exp/YOLO_11/v11_m/train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding model.yaml nc=80 with nc=4\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  2                  -1  1    111872  ultralytics.nn.modules.block.C3k2            [128, 256, 1, True, 0.25]     \n",
      "  3                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      "  4                  -1  1    444928  ultralytics.nn.modules.block.C3k2            [256, 512, 1, True, 0.25]     \n",
      "  5                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  6                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n",
      "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  8                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.C2PSA           [512, 512, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1   1642496  ultralytics.nn.modules.block.C3k2            [1024, 512, 1, True]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    542720  ultralytics.nn.modules.block.C3k2            [1024, 256, 1, True]          \n",
      " 17                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1   1511424  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True]           \n",
      " 20                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1642496  ultralytics.nn.modules.block.C3k2            [1024, 512, 1, True]          \n",
      " 23        [16, 19, 22]  1   1414108  ultralytics.nn.modules.head.Detect           [4, [256, 512, 512]]          \n",
      "YOLO11m summary: 409 layers, 20,056,092 parameters, 20,056,076 gradients, 68.2 GFLOPs\n",
      "\n",
      "Transferred 113/649 items from pretrained weights\n",
      "\u001b[34m\u001b[1mDDP:\u001b[0m debug command /home/sur06423/miniconda3/envs/yolov_env/bin/python -m torch.distributed.run --nproc_per_node 4 --master_port 41791 /home/sur06423/.config/Ultralytics/DDP/_temp_xc5grq7r140208996727680.py\n",
      "WARNING ⚠️ Python>=3.10 is required, but Python==3.9.19 is currently installed \n",
      "Ultralytics 8.3.13 🚀 Python-3.9.19 torch-2.4.1+cu121 CUDA:0 (NVIDIA RTX A6000, 48677MiB)\n",
      "                                                      CUDA:1 (NVIDIA RTX A6000, 48677MiB)\n",
      "                                                      CUDA:2 (NVIDIA RTX A6000, 48677MiB)\n",
      "                                                      CUDA:3 (NVIDIA RTX A6000, 48677MiB)\n",
      "Overriding model.yaml nc=80 with nc=4\n",
      "Transferred 643/649 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLO11n...\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5.35M/5.35M [00:00<00:00, 119MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/sur06423/project/Version_5_exp/Carla_Labeling-5/train/labels.cache... 4485 images, 430 backgrounds, 0 corrupt: 100%|██████████| 4485/4485 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/sur06423/project/Version_5_exp/Carla_Labeling-5/valid/labels.cache... 1274 images, 124 backgrounds, 0 corrupt: 100%|██████████| 1274/1274 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to /home/sur06423/project/Version_5_exp/YOLO_11/v11_m/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 106 weight(decay=0.0), 113 weight(decay=0.001), 112 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 24 dataloader workers\n",
      "Logging results to \u001b[1m/home/sur06423/project/Version_5_exp/YOLO_11/v11_m/train\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      1/100      16.6G      1.045      2.399      1.065          5        640: 100%|██████████| 36/36 [00:16<00:00,  2.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.736      0.431       0.48      0.277\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      2/100      16.8G     0.9378     0.8133     0.9854         17        640: 100%|██████████| 36/36 [00:15<00:00,  2.31it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:08<00:00,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377       0.61      0.402      0.388       0.22\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      3/100      16.8G      1.006     0.8511      1.025         37        640: 100%|██████████| 36/36 [00:14<00:00,  2.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.453      0.332      0.235      0.102\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      4/100      16.8G     0.9967     0.8094      1.036          8        640: 100%|██████████| 36/36 [00:15<00:00,  2.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.472      0.413      0.304      0.153\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      5/100      16.8G     0.9711     0.7604      1.012          6        640: 100%|██████████| 36/36 [00:14<00:00,  2.43it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:06<00:00,  2.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.627       0.42      0.387      0.204\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      6/100      16.8G     0.9293     0.6894     0.9873         26        640: 100%|██████████| 36/36 [00:14<00:00,  2.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:06<00:00,  2.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377       0.63      0.469      0.458      0.266\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      7/100      16.7G     0.9364     0.6843     0.9973          3        640: 100%|██████████| 36/36 [00:15<00:00,  2.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.697      0.444      0.483      0.288\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      8/100      16.8G      0.896     0.6305     0.9576         24        640: 100%|██████████| 36/36 [00:14<00:00,  2.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:06<00:00,  2.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.708      0.479      0.518      0.315\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      9/100      16.8G     0.8582     0.6205      0.966          1        640: 100%|██████████| 36/36 [00:14<00:00,  2.44it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:06<00:00,  2.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377       0.69      0.498      0.525      0.314\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     10/100      16.8G     0.8598     0.5958     0.9481          8        640: 100%|██████████| 36/36 [00:14<00:00,  2.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.758      0.526      0.577       0.36\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     11/100      16.8G     0.8796     0.5925      0.945         14        640: 100%|██████████| 36/36 [00:15<00:00,  2.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:06<00:00,  2.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.775      0.534      0.598      0.372\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     12/100      16.8G     0.8262     0.6341     0.9305          1        640: 100%|██████████| 36/36 [00:14<00:00,  2.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:06<00:00,  2.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.806      0.535      0.601      0.361\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     13/100      16.8G     0.8361     0.5481     0.9377         11        640: 100%|██████████| 36/36 [00:14<00:00,  2.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.796      0.555      0.626      0.388\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     14/100      16.8G      0.829      0.577     0.9327         14        640: 100%|██████████| 36/36 [00:14<00:00,  2.44it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:06<00:00,  2.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.819      0.552      0.622      0.384\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     15/100      16.8G       0.82     0.5335     0.9277         24        640: 100%|██████████| 36/36 [00:14<00:00,  2.44it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:06<00:00,  2.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.807      0.539      0.604       0.38\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     16/100      16.8G     0.8158     0.5305     0.9347          4        640: 100%|██████████| 36/36 [00:14<00:00,  2.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:06<00:00,  2.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.826      0.554      0.619      0.386\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     17/100      16.8G     0.8135     0.5523     0.9399         15        640: 100%|██████████| 36/36 [00:15<00:00,  2.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:06<00:00,  2.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.808      0.556      0.629       0.39\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     18/100      16.7G     0.7925     0.5378     0.9357          6        640: 100%|██████████| 36/36 [00:15<00:00,  2.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.836      0.565      0.637      0.395\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     19/100      16.8G     0.8083     0.5264     0.9253         12        640: 100%|██████████| 36/36 [00:15<00:00,  2.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:06<00:00,  2.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.825      0.588      0.648      0.406\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     20/100      16.6G     0.7888      0.513     0.9267         23        640: 100%|██████████| 36/36 [00:14<00:00,  2.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:06<00:00,  2.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.823      0.593      0.656       0.42\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     21/100      16.8G     0.7617     0.4934     0.9201          4        640: 100%|██████████| 36/36 [00:15<00:00,  2.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:06<00:00,  2.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.815      0.573      0.637      0.399\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     22/100      16.8G     0.7901     0.5097     0.9213          3        640: 100%|██████████| 36/36 [00:15<00:00,  2.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.847      0.588      0.662      0.421\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     23/100      16.7G     0.7561     0.4819     0.9145         27        640: 100%|██████████| 36/36 [00:14<00:00,  2.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:06<00:00,  2.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.832      0.591      0.665      0.423\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     24/100      16.8G     0.7541      0.472     0.9111          3        640: 100%|██████████| 36/36 [00:15<00:00,  2.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:06<00:00,  2.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.844      0.601       0.68       0.43\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     25/100      16.7G     0.7338     0.4709      0.907         20        640: 100%|██████████| 36/36 [00:15<00:00,  2.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:06<00:00,  2.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.811      0.614       0.67      0.428\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     26/100      16.6G     0.7333     0.4609     0.9202         18        640: 100%|██████████| 36/36 [00:14<00:00,  2.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:06<00:00,  2.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.841      0.604      0.677      0.432\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     27/100      16.8G     0.7527     0.4741     0.9047         11        640: 100%|██████████| 36/36 [00:14<00:00,  2.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:06<00:00,  2.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.831      0.612       0.67      0.428\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     28/100      16.8G     0.7296     0.4555     0.9033         20        640: 100%|██████████| 36/36 [00:15<00:00,  2.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:06<00:00,  2.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.843        0.6      0.666      0.427\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     29/100      16.8G     0.7085     0.4492      0.895          7        640: 100%|██████████| 36/36 [00:14<00:00,  2.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:06<00:00,  2.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.868      0.582      0.675      0.435\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     30/100      16.8G     0.7473     0.4621     0.9134         11        640: 100%|██████████| 36/36 [00:15<00:00,  2.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:06<00:00,  2.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.875      0.607      0.698      0.445\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     31/100      16.7G     0.7122     0.4483      0.899         19        640: 100%|██████████| 36/36 [00:14<00:00,  2.44it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:06<00:00,  2.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.842      0.618      0.683       0.44\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     32/100      16.7G      0.711     0.4423     0.8926         10        640: 100%|██████████| 36/36 [00:14<00:00,  2.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:06<00:00,  2.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.846      0.612      0.683      0.436\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     33/100      16.8G     0.7091     0.4336     0.8987         13        640: 100%|██████████| 36/36 [00:15<00:00,  2.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:06<00:00,  2.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.862      0.621      0.697      0.452\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     34/100      16.8G       0.71     0.4332     0.9025         11        640: 100%|██████████| 36/36 [00:15<00:00,  2.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:06<00:00,  2.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.856       0.62      0.704      0.455\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     35/100      16.6G     0.7187     0.4385     0.9028         21        640: 100%|██████████| 36/36 [00:14<00:00,  2.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:06<00:00,  2.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.858      0.624      0.702      0.453\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     36/100      16.8G     0.7021     0.4282     0.8997          9        640: 100%|██████████| 36/36 [00:15<00:00,  2.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:06<00:00,  2.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.866      0.627      0.705      0.454\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     37/100      16.7G     0.7025     0.4371     0.9004         10        640: 100%|██████████| 36/36 [00:15<00:00,  2.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:06<00:00,  2.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.886      0.613      0.706      0.457\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     38/100      16.7G     0.6727     0.4612     0.8799          0        640: 100%|██████████| 36/36 [00:15<00:00,  2.37it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.858      0.626      0.702      0.457\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     39/100      16.7G     0.6887     0.4196     0.8953         21        640: 100%|██████████| 36/36 [00:14<00:00,  2.43it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:06<00:00,  2.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.846      0.639      0.705      0.456\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     40/100      16.8G      0.697     0.4202     0.8933         15        640: 100%|██████████| 36/36 [00:15<00:00,  2.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:06<00:00,  2.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.869      0.623      0.699      0.454\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     41/100      16.8G     0.6672     0.4137     0.8917         10        640: 100%|██████████| 36/36 [00:14<00:00,  2.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.885      0.626      0.711      0.461\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     42/100      16.8G     0.6796     0.4089     0.8903         24        640: 100%|██████████| 36/36 [00:14<00:00,  2.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:06<00:00,  2.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.875      0.629      0.709       0.46\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     43/100      16.6G     0.6751     0.4094     0.9012          4        640: 100%|██████████| 36/36 [00:14<00:00,  2.44it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:06<00:00,  2.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.865      0.629      0.716      0.467\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     44/100      16.8G     0.6921     0.4102     0.8824         26        640: 100%|██████████| 36/36 [00:15<00:00,  2.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:06<00:00,  2.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.858      0.646      0.725      0.469\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     45/100      16.6G     0.6589     0.3955     0.8873          8        640: 100%|██████████| 36/36 [00:14<00:00,  2.43it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:06<00:00,  2.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.864      0.638      0.717      0.468\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     46/100      16.8G     0.6421     0.3849     0.8852          8        640: 100%|██████████| 36/36 [00:15<00:00,  2.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:06<00:00,  2.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.866      0.643      0.727      0.474\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     47/100      16.7G     0.6558     0.3901     0.8805         15        640: 100%|██████████| 36/36 [00:14<00:00,  2.44it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:06<00:00,  2.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.879      0.638      0.724      0.475\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     48/100      16.8G     0.6659      0.384     0.8822         16        640: 100%|██████████| 36/36 [00:15<00:00,  2.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:06<00:00,  2.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.874      0.652      0.727      0.477\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     49/100      16.7G     0.6836      0.481     0.8628          7        640: 100%|██████████| 36/36 [00:14<00:00,  2.44it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:06<00:00,  2.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.887      0.633      0.727      0.478\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     50/100      16.8G     0.6731     0.3931     0.8801         17        640: 100%|██████████| 36/36 [00:14<00:00,  2.43it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:06<00:00,  2.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.865       0.66      0.727      0.478\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     51/100      16.8G     0.6489     0.3829     0.8874         10        640: 100%|██████████| 36/36 [00:15<00:00,  2.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:06<00:00,  2.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.868      0.653      0.728      0.476\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     52/100      16.8G     0.6424     0.3784     0.8844          5        640: 100%|██████████| 36/36 [00:14<00:00,  2.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:06<00:00,  2.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.851      0.648      0.724      0.475\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     53/100      16.7G     0.6384     0.3838     0.8859          8        640: 100%|██████████| 36/36 [00:14<00:00,  2.44it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:06<00:00,  2.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.871      0.626      0.717      0.472\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     54/100      16.8G     0.6178     0.3769     0.8742         14        640: 100%|██████████| 36/36 [00:14<00:00,  2.43it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:06<00:00,  2.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.881      0.644      0.728      0.484\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     55/100      16.8G     0.6414     0.3873       0.88         21        640: 100%|██████████| 36/36 [00:15<00:00,  2.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:06<00:00,  2.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.882      0.646      0.731      0.483\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     56/100      16.7G     0.6201     0.3667     0.8784          5        640: 100%|██████████| 36/36 [00:14<00:00,  2.44it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:06<00:00,  2.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.865      0.647      0.728      0.483\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     57/100      16.8G      0.639     0.3709     0.8717         13        640: 100%|██████████| 36/36 [00:14<00:00,  2.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:06<00:00,  2.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377       0.88      0.651      0.735      0.486\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     58/100      16.7G     0.6315     0.3685     0.8842         21        640: 100%|██████████| 36/36 [00:14<00:00,  2.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:06<00:00,  2.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.885       0.65      0.742      0.493\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     59/100      16.8G     0.6332     0.3661     0.8734         12        640: 100%|██████████| 36/36 [00:14<00:00,  2.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:06<00:00,  2.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.885      0.647      0.741      0.494\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     60/100      16.7G     0.6211     0.3652     0.8686         18        640: 100%|██████████| 36/36 [00:14<00:00,  2.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:06<00:00,  2.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377       0.88      0.657      0.744      0.499\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     61/100      16.8G     0.6302     0.3691     0.8733         39        640: 100%|██████████| 36/36 [00:15<00:00,  2.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:06<00:00,  2.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.893      0.655      0.745      0.496\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     62/100      16.8G     0.6095     0.3564     0.8748         33        640: 100%|██████████| 36/36 [00:14<00:00,  2.43it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:06<00:00,  2.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.878      0.657      0.742      0.499\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     63/100      16.8G     0.6234     0.3609     0.8683         13        640: 100%|██████████| 36/36 [00:15<00:00,  2.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:06<00:00,  2.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.901      0.648      0.739      0.494\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     64/100      16.7G     0.6269     0.3566     0.8644          6        640: 100%|██████████| 36/36 [00:14<00:00,  2.44it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:06<00:00,  2.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.864      0.665      0.743        0.5\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     65/100      16.8G     0.6325     0.3568      0.871          3        640: 100%|██████████| 36/36 [00:14<00:00,  2.44it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:06<00:00,  2.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.863      0.672      0.744      0.495\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     66/100      16.8G     0.6284     0.3585     0.8799         10        640: 100%|██████████| 36/36 [00:15<00:00,  2.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:06<00:00,  2.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.879      0.672      0.755      0.502\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     67/100      16.8G     0.6219     0.3605     0.8719         19        640: 100%|██████████| 36/36 [00:14<00:00,  2.44it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:06<00:00,  2.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.855      0.676       0.75      0.505\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     68/100      16.7G     0.5916     0.3458     0.8588         19        640: 100%|██████████| 36/36 [00:15<00:00,  2.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:06<00:00,  2.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.873      0.673      0.752      0.504\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     69/100      16.7G     0.6178     0.3574     0.8697         16        640: 100%|██████████| 36/36 [00:14<00:00,  2.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:06<00:00,  2.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.883      0.663      0.749      0.503\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     70/100      16.8G     0.6049     0.3476     0.8674         24        640: 100%|██████████| 36/36 [00:15<00:00,  2.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:06<00:00,  2.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377       0.87      0.676      0.754      0.509\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     71/100      16.8G     0.5992     0.3366     0.8682         17        640: 100%|██████████| 36/36 [00:14<00:00,  2.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:06<00:00,  2.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.891       0.66      0.752      0.506\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     72/100      16.8G     0.5983     0.3387     0.8654         12        640: 100%|██████████| 36/36 [00:14<00:00,  2.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:06<00:00,  2.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.878      0.666      0.757      0.511\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     73/100      16.8G     0.5942     0.3466     0.8664         13        640: 100%|██████████| 36/36 [00:14<00:00,  2.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:06<00:00,  2.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.881      0.669      0.757      0.507\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     74/100      16.6G     0.5884     0.3377     0.8721         11        640: 100%|██████████| 36/36 [00:15<00:00,  2.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:06<00:00,  2.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.874      0.669      0.753      0.507\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     75/100      16.8G     0.5944      0.335     0.8643          6        640: 100%|██████████| 36/36 [00:14<00:00,  2.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:06<00:00,  2.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377       0.88      0.664      0.757      0.513\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     76/100      16.8G     0.6007     0.3372     0.8592          8        640: 100%|██████████| 36/36 [00:14<00:00,  2.43it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.892      0.665      0.756      0.514\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     77/100      16.6G     0.5973     0.3362     0.8616         22        640: 100%|██████████| 36/36 [00:14<00:00,  2.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:06<00:00,  2.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.886      0.666      0.753       0.51\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     78/100      16.7G     0.5998     0.3357     0.8797          4        640: 100%|██████████| 36/36 [00:15<00:00,  2.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.889      0.675      0.762      0.513\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     79/100      16.8G     0.5906     0.3289     0.8671         13        640: 100%|██████████| 36/36 [00:15<00:00,  2.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:06<00:00,  2.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377       0.88      0.677      0.763       0.52\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     80/100      16.8G     0.5804     0.3264     0.8601         36        640: 100%|██████████| 36/36 [00:14<00:00,  2.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:06<00:00,  2.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.864      0.687      0.759      0.514\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     81/100      16.8G     0.5762     0.3294     0.8629          7        640: 100%|██████████| 36/36 [00:14<00:00,  2.43it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:06<00:00,  2.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.867      0.687      0.763      0.515\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     82/100      16.6G     0.5786     0.3314     0.8604          9        640: 100%|██████████| 36/36 [00:15<00:00,  2.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:06<00:00,  2.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.874      0.673      0.763      0.515\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     83/100      16.8G       0.58     0.3243     0.8604          8        640: 100%|██████████| 36/36 [00:14<00:00,  2.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.873       0.68      0.767      0.522\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     84/100      16.8G     0.5821     0.3293     0.8614          8        640: 100%|██████████| 36/36 [00:14<00:00,  2.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:06<00:00,  2.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.871      0.673       0.76      0.515\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     85/100      16.7G     0.5794     0.3233     0.8681         11        640: 100%|██████████| 36/36 [00:15<00:00,  2.37it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:06<00:00,  2.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.877      0.673      0.765      0.521\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     86/100      16.7G     0.6112     0.4615     0.9128          3        640: 100%|██████████| 36/36 [00:15<00:00,  2.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:06<00:00,  2.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.892       0.67      0.763       0.52\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     87/100      16.7G     0.5735     0.3154     0.8602         14        640: 100%|██████████| 36/36 [00:15<00:00,  2.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:06<00:00,  2.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.872      0.681      0.766      0.522\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     88/100      16.8G     0.5716     0.3158     0.8582         16        640: 100%|██████████| 36/36 [00:14<00:00,  2.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:06<00:00,  2.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.885      0.676      0.769      0.524\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     89/100      16.8G     0.5415     0.3022     0.8611         14        640: 100%|██████████| 36/36 [00:14<00:00,  2.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:06<00:00,  2.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.869      0.686      0.771      0.523\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     90/100      16.6G      0.548     0.3174     0.8661          3        640: 100%|██████████| 36/36 [00:14<00:00,  2.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:06<00:00,  2.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.889       0.67      0.768      0.522\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     91/100      16.8G     0.6176     0.3196     0.8473         13        640: 100%|██████████| 36/36 [00:15<00:00,  2.34it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:06<00:00,  2.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.879      0.679      0.768       0.52\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     92/100      16.7G     0.6146     0.3152     0.8473         13        640: 100%|██████████| 36/36 [00:14<00:00,  2.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:06<00:00,  2.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377       0.88      0.679      0.768      0.521\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     93/100      16.8G     0.6054     0.3131     0.8417          7        640: 100%|██████████| 36/36 [00:14<00:00,  2.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:06<00:00,  2.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.884       0.68      0.771      0.524\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     94/100      16.8G     0.6206     0.3204     0.8444          6        640: 100%|██████████| 36/36 [00:14<00:00,  2.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:06<00:00,  2.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.879      0.675       0.77      0.523\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     95/100      16.7G     0.6208     0.3189     0.8401         31        640: 100%|██████████| 36/36 [00:14<00:00,  2.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:06<00:00,  2.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.897      0.669      0.768      0.523\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     96/100      16.8G      0.611     0.3162     0.8468         13        640: 100%|██████████| 36/36 [00:15<00:00,  2.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.876      0.682      0.772      0.524\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     97/100      16.8G     0.6113     0.3141      0.843         13        640: 100%|██████████| 36/36 [00:14<00:00,  2.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:06<00:00,  2.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.882      0.679      0.773      0.529\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     98/100      16.7G     0.6136     0.3206      0.838          3        640: 100%|██████████| 36/36 [00:15<00:00,  2.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:06<00:00,  2.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.886      0.674      0.771      0.527\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     99/100      16.7G     0.6015      0.306     0.8401         40        640: 100%|██████████| 36/36 [00:14<00:00,  2.44it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:06<00:00,  2.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.894      0.669      0.771      0.529\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    100/100      16.7G     0.5967     0.3065     0.8427          6        640: 100%|██████████| 36/36 [00:14<00:00,  2.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:06<00:00,  2.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377       0.88      0.678      0.772      0.529\n",
      "\n",
      "100 epochs completed in 0.867 hours.\n",
      "Optimizer stripped from /home/sur06423/project/Version_5_exp/YOLO_11/v11_m/train/weights/last.pt, 40.5MB\n",
      "Optimizer stripped from /home/sur06423/project/Version_5_exp/YOLO_11/v11_m/train/weights/best.pt, 40.5MB\n",
      "\n",
      "Validating /home/sur06423/project/Version_5_exp/YOLO_11/v11_m/train/weights/best.pt...\n",
      "Ultralytics 8.3.13 🚀 Python-3.9.19 torch-2.4.1+cu121 CUDA:0 (NVIDIA RTX A6000, 48677MiB)\n",
      "                                                      CUDA:1 (NVIDIA RTX A6000, 48677MiB)\n",
      "                                                      CUDA:2 (NVIDIA RTX A6000, 48677MiB)\n",
      "                                                      CUDA:3 (NVIDIA RTX A6000, 48677MiB)\n",
      "YOLO11m summary (fused): 303 layers, 20,033,116 parameters, 0 gradients, 67.7 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:10<00:00,  1.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.895       0.67      0.773      0.529\n",
      "            Pedestrian        333        600      0.848      0.698      0.794      0.489\n",
      "         Traffic_Signs        309        434      0.894      0.622      0.728      0.459\n",
      "               Vehicle       1034       2820      0.937      0.892      0.944      0.774\n",
      "         traffic_light        660       3523      0.901      0.467      0.624      0.395\n",
      "Speed: 0.1ms preprocess, 2.7ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
      "Results saved to \u001b[1m/home/sur06423/project/Version_5_exp/YOLO_11/v11_m/train\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Train the model: https://docs.ultralytics.com/modes/train/#train-settings\n",
    "model.train(data=\"/home/sur06423/project/Version_5_exp/Carla_Labeling-5/data.yaml\", # \tPath to the dataset configuration file (e.g., coco8.yaml). This file contains dataset-specific parameters, including paths to training and validation data, class names, and number of classes.\n",
    "            epochs=100, # Total number of training epochs. Each epoch represents a full pass over the entire dataset. Adjusting this value can affect training duration and model performance.\n",
    "            patience=10, # Number of epochs to wait without improvement in validation metrics before early stopping the training. Helps prevent overfitting by stopping training when performance plateaus.\n",
    "            batch=128, # Batch size, with three modes: set as an integer (e.g., batch=16), auto mode for 60% GPU memory utilization (batch=-1), or auto mode with specified utilization fraction (batch=0.70).\n",
    "            imgsz=640, # Target image size for training. All images are resized to this dimension before being fed into the model. Affects model accuracy and computational complexity.\n",
    "            save=True, # Enables saving of training checkpoints and final model weights. Useful for resuming training or model deployment.\n",
    "            save_period = 1, # Frequency of saving model checkpoints, specified in epochs. A value of -1 disables this feature. Useful for saving interim models during long training sessions.\n",
    "            device=[0,1,2,3], # Specifies the computational device(s) for training: a single GPU (device=0), multiple GPUs (device=0,1), CPU (device=cpu), or MPS for Apple silicon (device=mps).\n",
    "            workers=6, # Number of worker threads for data loading (per RANK if Multi-GPU training). Influences the speed of data preprocessing and feeding into the model, especially useful in multi-GPU setups.\n",
    "            project=\"/home/sur06423/project/Version_5_exp/YOLO_11/v11_m\", # Name of the project directory where training outputs are saved. Allows for organized storage of different experiments.\n",
    "            pretrained = True, # Determines whether to start training from a pretrained model. Can be a boolean value or a string path to a specific model from which to load weights. Enhances training efficiency and model performance.\n",
    "            optimizer = \"auto\", # Choice of optimizer for training. Options include SGD, Adam, AdamW, NAdam, RAdam, RMSProp etc., or auto for automatic selection based on model configuration. Affects convergence speed and stability.\n",
    "            verbose = True, # Enables verbose output during training, providing detailed logs and progress updates. Useful for debugging and closely monitoring the training process.\n",
    "            seed = 0, # Sets the random seed for training, ensuring reproducibility of results across runs with the same configurations.\n",
    "            amp = True, # Enables Automatic Mixed Precision (AMP) training, reducing memory usage and possibly speeding up training with minimal impact on accuracy.\n",
    "            profile =True, # Enables profiling of ONNX and TensorRT speeds during training, useful for optimizing model deployment.\n",
    "            val=True, # Enables validation during training, allowing for periodic evaluation of model performance on a separate dataset.\n",
    "            plots = True, #Generates and saves plots of training and validation metrics, as well as prediction examples, providing visual insights into model performance and learning progression.                \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results on Validation set:\n",
    "100 epochs completed in 0.867 hours.\n",
    "Optimizer stripped from /home/sur06423/project/Version_5_exp/YOLO_11/v11_m/train/weights/last.pt, 40.5MB\n",
    "Optimizer stripped from /home/sur06423/project/Version_5_exp/YOLO_11/v11_m/train/weights/best.pt, 40.5MB\n",
    "\n",
    "Validating /home/sur06423/project/Version_5_exp/YOLO_11/v11_m/train/weights/best.pt...\n",
    "Ultralytics 8.3.13 🚀 Python-3.9.19 torch-2.4.1+cu121 CUDA:0 (NVIDIA RTX A6000, 48677MiB)\n",
    "                                                      CUDA:1 (NVIDIA RTX A6000, 48677MiB)\n",
    "                                                      CUDA:2 (NVIDIA RTX A6000, 48677MiB)\n",
    "                                                      CUDA:3 (NVIDIA RTX A6000, 48677MiB)\n",
    "YOLO11m summary (fused): 303 layers, 20,033,116 parameters, 0 gradients, 67.7 GFLOPs\n",
    "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:10<00:00,  1.91it/s]\n",
    "                   all       1274       7377      0.895       0.67      0.773      0.529\n",
    "            Pedestrian        333        600      0.848      0.698      0.794      0.489\n",
    "         Traffic_Signs        309        434      0.894      0.622      0.728      0.459\n",
    "               Vehicle       1034       2820      0.937      0.892      0.944      0.774\n",
    "         traffic_light        660       3523      0.901      0.467      0.624      0.395\n",
    "Speed: 0.1ms preprocess, 2.7ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
    "Results saved to /home/sur06423/project/Version_5_exp/YOLO_11/v11_m/train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the results on Test dataset\n",
    "- The above results was on the validation set of the Carla_labeling-v5 dataset (See the Image counts)\n",
    "- Now we need to calculate the metrics on the test set of the Carla_labeling-v5 dataset containing only 641 images.\n",
    "- Below is the script to do so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.13 🚀 Python-3.9.19 torch-2.4.1+cu121 CUDA:0 (NVIDIA RTX A6000, 48677MiB)\n",
      "YOLO11m summary (fused): 303 layers, 20,033,116 parameters, 0 gradients, 67.7 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/sur06423/project/Version_5_exp/Carla_Labeling-5/test/labels.cache... 641 images, 53 backgrounds, 0 corrupt: 100%|██████████| 641/641 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:12<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        641       3701      0.875       0.67      0.802      0.588\n",
      "            Pedestrian        182        332       0.78      0.717      0.803      0.541\n",
      "         Traffic_Signs        168        230      0.877      0.617      0.777      0.523\n",
      "               Vehicle        528       1377      0.947       0.89      0.939      0.816\n",
      "         traffic_light        338       1762      0.896      0.455      0.688      0.473\n",
      "Speed: 0.4ms preprocess, 5.2ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
      "Saving runs/detect/val/predictions.json...\n",
      "Results saved to \u001b[1mruns/detect/val\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load YOLOv10s model from scratch\n",
    "# model = YOLO(\"yolov10s.pt\")\n",
    "# Load YOLOv10s Best weights on carla dataset\n",
    "model = YOLO(\"/home/sur06423/project/Version_5_exp/YOLO_11/v11_m/train/weights/last.pt\")\n",
    "\n",
    "# Train the model: https://docs.ultralytics.com/modes/train/#train-settings\n",
    "validation_results = model.val(data=\"/home/sur06423/project/Version_5_exp/Carla_Labeling-5/data.yaml\", \n",
    "            batch=128, \n",
    "            imgsz=640,\n",
    "            save_json = True, # If True, saves the results to a JSON file for further analysis or integration with other tools.\n",
    "            conf=0.25, # Sets the minimum confidence threshold for detections. Detections with confidence below this threshold are discarded.\n",
    "            iou=0.6, # Sets the Intersection Over Union (IoU) threshold for Non-Maximum Suppression (NMS). Helps in reducing duplicate detections.\n",
    "            device=0, \n",
    "            split=\"test\",              \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results on Last checpoint (100th epoch):\n",
    "Ultralytics 8.3.13 🚀 Python-3.9.19 torch-2.4.1+cu121 CUDA:0 (NVIDIA RTX A6000, 48677MiB)\n",
    "YOLO11m summary (fused): 303 layers, 20,033,116 parameters, 0 gradients, 67.7 GFLOPs\n",
    "val: Scanning /home/sur06423/project/Version_5_exp/Carla_Labeling-5/test/labels.cache... 641 images, 53 backgrounds, 0 corrupt: 100%|██████████| 641/641 [00:00<?, ?it/s]\n",
    "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:12<00:00,  2.04s/it]\n",
    "                   all        641       3701      0.875       0.67      0.802      0.588\n",
    "            Pedestrian        182        332       0.78      0.717      0.803      0.541\n",
    "         Traffic_Signs        168        230      0.877      0.617      0.777      0.523\n",
    "               Vehicle        528       1377      0.947       0.89      0.939      0.816\n",
    "         traffic_light        338       1762      0.896      0.455      0.688      0.473\n",
    "Speed: 0.4ms preprocess, 5.2ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
    "Saving runs/detect/val/predictions.json...\n",
    "Results saved to runs/detect/val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results on Test Set using Best Checkpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.13 🚀 Python-3.9.19 torch-2.4.1+cu121 CUDA:0 (NVIDIA RTX A6000, 48677MiB)\n",
      "YOLO11m summary (fused): 303 layers, 20,033,116 parameters, 0 gradients, 67.7 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/sur06423/project/Version_5_exp/Carla_Labeling-5/test/labels.cache... 641 images, 53 backgrounds, 0 corrupt: 100%|██████████| 641/641 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:11<00:00,  1.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        641       3701      0.882      0.669      0.803      0.587\n",
      "            Pedestrian        182        332      0.788      0.705        0.8      0.538\n",
      "         Traffic_Signs        168        230      0.894      0.626      0.786      0.523\n",
      "               Vehicle        528       1377       0.95      0.888      0.938      0.815\n",
      "         traffic_light        338       1762      0.896      0.457      0.689      0.471\n",
      "Speed: 0.3ms preprocess, 4.8ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "Saving runs/detect/val2/predictions.json...\n",
      "Results saved to \u001b[1mruns/detect/val2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load YOLOv10s model from scratch\n",
    "# model = YOLO(\"yolov10s.pt\")\n",
    "# Load the model\n",
    "model = YOLO(\"/home/sur06423/project/Version_5_exp/YOLO_11/v11_m/train/weights/best.pt\")\n",
    "\n",
    "# Train the model: https://docs.ultralytics.com/modes/train/#train-settings\n",
    "validation_results = model.val(data=\"/home/sur06423/project/Version_5_exp/Carla_Labeling-5/data.yaml\", \n",
    "            batch=128, \n",
    "            imgsz=640,\n",
    "            save_json = True, # If True, saves the results to a JSON file for further analysis or integration with other tools.\n",
    "            conf=0.25, # Sets the minimum confidence threshold for detections. Detections with confidence below this threshold are discarded.\n",
    "            iou=0.6, # Sets the Intersection Over Union (IoU) threshold for Non-Maximum Suppression (NMS). Helps in reducing duplicate detections.\n",
    "            device=0, \n",
    "            split=\"test\",              \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['date', 'version', 'license', 'docs', 'epoch', 'best_fitness', 'model', 'ema', 'updates', 'optimizer', 'train_args', 'train_metrics', 'train_results'])\n"
     ]
    }
   ],
   "source": [
    "print(checkpoint.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taking the Optimal value from the F1-Confidence curve for Optimal Confidence\n",
    "- Optimal Confidence YOLO11m - 0.317\n",
    "- IoU threshold : 0.5\n",
    "- Results save d at: runs/detect/val3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ Python>=3.10 is required, but Python==3.9.19 is currently installed \n",
      "Ultralytics 8.3.13 🚀 Python-3.9.19 torch-2.4.1+cu121 CUDA:0 (NVIDIA RTX A6000, 48677MiB)\n",
      "YOLO11m summary (fused): 303 layers, 20,033,116 parameters, 0 gradients, 67.7 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/sur06423/project/Version_5_exp/Carla_Labeling-5/test/labels.cache... 641 images, 53 backgrounds, 0 corrupt: 100%|██████████| 641/641 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:08<00:00,  1.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        641       3701      0.896      0.655      0.799       0.59\n",
      "            Pedestrian        182        332      0.825      0.696      0.801      0.543\n",
      "         Traffic_Signs        168        230       0.89        0.6      0.772      0.524\n",
      "               Vehicle        528       1377      0.956      0.885      0.937      0.816\n",
      "         traffic_light        338       1762      0.913       0.44      0.686      0.475\n",
      "Speed: 2.0ms preprocess, 5.1ms inference, 0.0ms loss, 1.7ms postprocess per image\n",
      "Saving runs/detect/val3/predictions.json...\n",
      "Results saved to \u001b[1mruns/detect/val3\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load YOLOv10s model from scratch\n",
    "# model = YOLO(\"yolov10s.pt\")\n",
    "# Load YOLOv10s Best weights on carla dataset\n",
    "model = YOLO(\"/home/sur06423/project/Version_5_exp/YOLO_11/v11_m/train/weights/last.pt\")\n",
    "\n",
    "# Train the model: https://docs.ultralytics.com/modes/train/#train-settings\n",
    "validation_results = model.val(data=\"/home/sur06423/project/Version_5_exp/Carla_Labeling-5/data.yaml\", \n",
    "            batch=128, \n",
    "            imgsz=640,\n",
    "            save_json = True, # If True, saves the results to a JSON file for further analysis or integration with other tools.\n",
    "            conf=0.317, # Sets the optimal confidence threshold for detections. Detections with confidence below this threshold are discarded.\n",
    "            iou=0.5, # Sets the Intersection Over Union (IoU) threshold for Non-Maximum Suppression (NMS). Helps in reducing duplicate detections.\n",
    "            device=0, \n",
    "            split=\"test\",              \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taking the Optimal value from the F1-Confidence curve for Optimal Confidence and best checkpoint for testing.\n",
    "- Optimal Confidence YOLO11m - 0.317\n",
    "- IoU threshold : 0.5\n",
    "- Results save d at: runs/detect/val4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ Python>=3.10 is required, but Python==3.9.19 is currently installed \n",
      "Ultralytics 8.3.13 🚀 Python-3.9.19 torch-2.4.1+cu121 CUDA:0 (NVIDIA RTX A6000, 48677MiB)\n",
      "YOLO11m summary (fused): 303 layers, 20,033,116 parameters, 0 gradients, 67.7 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/sur06423/project/Version_5_exp/Carla_Labeling-5/test/labels.cache... 641 images, 53 backgrounds, 0 corrupt: 100%|██████████| 641/641 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:08<00:00,  1.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        641       3701      0.902      0.652      0.799      0.588\n",
      "            Pedestrian        182        332      0.831      0.681      0.796      0.541\n",
      "         Traffic_Signs        168        230      0.908      0.604      0.779      0.524\n",
      "               Vehicle        528       1377      0.957      0.882      0.935      0.814\n",
      "         traffic_light        338       1762      0.912      0.442      0.687      0.474\n",
      "Speed: 1.7ms preprocess, 5.5ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Saving runs/detect/val4/predictions.json...\n",
      "Results saved to \u001b[1mruns/detect/val4\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"/home/sur06423/project/Version_5_exp/YOLO_11/v11_m/train/weights/best.pt\")\n",
    "\n",
    "# Train the model: https://docs.ultralytics.com/modes/train/#train-settings\n",
    "validation_results = model.val(data=\"/home/sur06423/project/Version_5_exp/Carla_Labeling-5/data.yaml\", \n",
    "            batch=128, \n",
    "            imgsz=640,\n",
    "            save_json = True, # If True, saves the results to a JSON file for further analysis or integration with other tools.\n",
    "            conf=0.317, # Sets the optimal confidence threshold for detections. Detections with confidence below this threshold are discarded.\n",
    "            iou=0.5, # Sets the Intersection Over Union (IoU) threshold for Non-Maximum Suppression (NMS). Helps in reducing duplicate detections.\n",
    "            device=0, \n",
    "            split=\"test\",              \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best + Taking the Optimal value from the F1-Confidence + IoU 0.6\n",
    "- Optimal Confidence YOLO11m - 0.317\n",
    "- IoU threshold : 0.6\n",
    "- Results save d at: runs/detect/val5\n",
    "- Best Epoch : 99 th Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ Python>=3.10 is required, but Python==3.9.19 is currently installed \n",
      "Ultralytics 8.3.13 🚀 Python-3.9.19 torch-2.4.1+cu121 CUDA:0 (NVIDIA RTX A6000, 48677MiB)\n",
      "YOLO11m summary (fused): 303 layers, 20,033,116 parameters, 0 gradients, 67.7 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/sur06423/project/Version_5_exp/Carla_Labeling-5/test/labels.cache... 641 images, 53 backgrounds, 0 corrupt: 100%|██████████| 641/641 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:08<00:00,  1.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        641       3701      0.901      0.653      0.799      0.588\n",
      "            Pedestrian        182        332      0.828      0.684      0.798      0.541\n",
      "         Traffic_Signs        168        230      0.908      0.604      0.779      0.524\n",
      "               Vehicle        528       1377      0.956      0.882      0.935      0.814\n",
      "         traffic_light        338       1762      0.911      0.442      0.686      0.473\n",
      "Speed: 1.9ms preprocess, 5.1ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Saving runs/detect/val5/predictions.json...\n",
      "Results saved to \u001b[1mruns/detect/val5\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"/home/sur06423/project/Version_5_exp/YOLO_11/v11_m/train/weights/best.pt\")\n",
    "\n",
    "# Train the model: https://docs.ultralytics.com/modes/train/#train-settings\n",
    "validation_results = model.val(data=\"/home/sur06423/project/Version_5_exp/Carla_Labeling-5/data.yaml\", \n",
    "            batch=128, \n",
    "            imgsz=640,\n",
    "            save_json = True, # If True, saves the results to a JSON file for further analysis or integration with other tools.\n",
    "            conf=0.317, # Sets the optimal confidence threshold for detections. Detections with confidence below this threshold are discarded.\n",
    "            iou=0.6, # Sets the Intersection Over Union (IoU) threshold for Non-Maximum Suppression (NMS). Helps in reducing duplicate detections.\n",
    "            device=0, \n",
    "            split=\"test\",              \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.13 🚀 Python-3.9.19 torch-2.4.1+cu121 CUDA:0 (NVIDIA RTX A6000, 48677MiB)\n",
      "YOLO11m summary (fused): 303 layers, 20,033,116 parameters, 0 gradients, 67.7 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/sur06423/project/Version_5_exp/Carla_Labeling-5/test/labels.cache... 641 images, 53 backgrounds, 0 corrupt: 100%|██████████| 641/641 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:09<00:00,  1.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        641       3701      0.891      0.653      0.797      0.587\n",
      "            Pedestrian        182        332      0.817      0.684      0.795      0.539\n",
      "         Traffic_Signs        168        230      0.903      0.604      0.777      0.523\n",
      "               Vehicle        528       1377      0.946      0.882      0.934      0.813\n",
      "         traffic_light        338       1762        0.9      0.443      0.683      0.471\n",
      "Speed: 1.7ms preprocess, 4.7ms inference, 0.0ms loss, 0.5ms postprocess per image\n",
      "Saving runs/detect/val6/predictions.json...\n",
      "Results saved to \u001b[1mruns/detect/val6\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"/home/sur06423/project/Version_5_exp/YOLO_11/v11_m/train/weights/best.pt\")\n",
    "\n",
    "# Train the model: https://docs.ultralytics.com/modes/train/#train-settings\n",
    "validation_results = model.val(data=\"/home/sur06423/project/Version_5_exp/Carla_Labeling-5/data.yaml\", \n",
    "            batch=128, \n",
    "            imgsz=640,\n",
    "            save_json = True, # If True, saves the results to a JSON file for further analysis or integration with other tools.\n",
    "            conf=0.317, # Sets the optimal confidence threshold for detections. Detections with confidence below this threshold are discarded.\n",
    "            iou=0.75, # Sets the Intersection Over Union (IoU) threshold for Non-Maximum Suppression (NMS). Helps in reducing duplicate detections.\n",
    "            device=0, \n",
    "            split=\"test\",              \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.13 🚀 Python-3.9.19 torch-2.4.1+cu121 CUDA:0 (NVIDIA RTX A6000, 48677MiB)\n",
      "YOLO11m summary (fused): 303 layers, 20,033,116 parameters, 0 gradients, 67.7 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/sur06423/project/Version_5_exp/Carla_Labeling-5/test/labels.cache... 641 images, 53 backgrounds, 0 corrupt: 100%|██████████| 641/641 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:08<00:00,  1.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        641       3701      0.707      0.606      0.696      0.523\n",
      "            Pedestrian        182        332       0.49      0.617      0.584      0.414\n",
      "         Traffic_Signs        168        230      0.801      0.557      0.717      0.487\n",
      "               Vehicle        528       1377      0.793      0.858      0.896      0.781\n",
      "         traffic_light        338       1762      0.744      0.391      0.586      0.408\n",
      "Speed: 1.8ms preprocess, 4.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Saving runs/detect/val7/predictions.json...\n",
      "Results saved to \u001b[1mruns/detect/val7\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"/home/sur06423/project/Version_5_exp/YOLO_11/v11_m/train/weights/best.pt\")\n",
    "\n",
    "# Train the model: https://docs.ultralytics.com/modes/train/#train-settings\n",
    "validation_results = model.val(data=\"/home/sur06423/project/Version_5_exp/Carla_Labeling-5/data.yaml\", \n",
    "            batch=128, \n",
    "            imgsz=640,\n",
    "            save_json = True, # If True, saves the results to a JSON file for further analysis or integration with other tools.\n",
    "            conf=0.317, # Sets the optimal confidence threshold for detections. Detections with confidence below this threshold are discarded.\n",
    "            iou=0.95, # Sets the Intersection Over Union (IoU) threshold for Non-Maximum Suppression (NMS). Helps in reducing duplicate detections.\n",
    "            device=0, \n",
    "            split=\"test\",              \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seperate evaluation on the training set\n",
    "- Follow the link for more instructions: https://github.com/orgs/ultralytics/discussions/8790"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.13 🚀 Python-3.9.19 torch-2.4.1+cu121 CUDA:0 (NVIDIA RTX A6000, 48677MiB)\n",
      "YOLO11m summary (fused): 303 layers, 20,033,116 parameters, 0 gradients, 67.7 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/sur06423/project/Version_5_exp/Carla_Labeling-5/train/labels.cache... 4485 images, 430 backgrounds, 0 corrupt: 100%|██████████| 4485/4485 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:39<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4485      26788      0.913      0.711      0.836      0.652\n",
      "            Pedestrian       1229       2227      0.872      0.794      0.873      0.647\n",
      "         Traffic_Signs       1093       1459      0.901      0.674      0.813      0.586\n",
      "               Vehicle       3636      10031      0.959      0.921      0.957      0.854\n",
      "         traffic_light       2373      13071       0.92      0.456        0.7      0.518\n",
      "Speed: 0.4ms preprocess, 4.8ms inference, 0.0ms loss, 0.6ms postprocess per image\n",
      "Saving runs/detect/val9/predictions.json...\n",
      "Results saved to \u001b[1mruns/detect/val9\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load your model\n",
    "model = YOLO('/home/sur06423/project/Version_5_exp/YOLO_11/v11_m/train/weights/best.pt')  # replace with your model path\n",
    "\n",
    "# Validate on custom dataset\n",
    "results = model.val(data='/home/sur06423/project/Version_5_exp/Carla_Labeling-5/data.yaml',\n",
    "            batch=128, \n",
    "            imgsz=640,\n",
    "            save_json = True, # If True, saves the results to a JSON file for further analysis or integration with other tools.\n",
    "            conf=0.25, # Sets the optimal confidence threshold for detections. Detections with confidence below this threshold are discarded.\n",
    "            iou=0.6, # Sets the Intersection Over Union (IoU) threshold for Non-Maximum Suppression (NMS). Helps in reducing duplicate detections.\n",
    "            device=0, \n",
    "            split=\"train\", \n",
    ")  # Ensure your YAML points to your desired dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook is complete.\n",
    "- All the cell are executed and saved for later use.\n",
    "- Results are saved in the corresponding directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
