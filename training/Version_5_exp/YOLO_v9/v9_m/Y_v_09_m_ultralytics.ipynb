{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ultralytics Framework for YOLOv9 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of available GPUs: 4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Number of GPUs available\n",
    "num_gpus = torch.cuda.device_count()\n",
    "\n",
    "print(f\"Number of available GPUs: {num_gpus}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yolov09m Model Training on:\n",
    "- Carla_Labelling-v5 dataset\n",
    "- Train: 70% = 4485 Images\n",
    "- Validation: 20% = 1274 Images\n",
    "- Test: 10% = 641 Images\n",
    "\n",
    "- Hyperparameters are on automatic settings using Ultralytics package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov9m.pt to 'yolov9m.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39.1M/39.1M [00:00<00:00, 200MB/s]\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load YOLOv10n model from scratch\n",
    "model = YOLO(\"yolov9m.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate the pretrained weights by running inference on an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 4 horses, 81.1ms\n",
      "Speed: 8.7ms preprocess, 81.1ms inference, 461.2ms postprocess per image at shape (1, 3, 448, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error: no \"view\" rule for type \"image/png\" passed its test case\n",
      "       (for more information, add \"--debug=1\" on the command line)\n"
     ]
    }
   ],
   "source": [
    "# Run batched inference on a list of images\n",
    "results = model([\"/home/sur06423/project/1.jpg\"])  # return a list of Results objects\n",
    "\n",
    "# Process results list\n",
    "for result in results:\n",
    "    boxes = result.boxes  # Boxes object for bounding box outputs\n",
    "    masks = result.masks  # Masks object for segmentation masks outputs\n",
    "    keypoints = result.keypoints  # Keypoints object for pose outputs\n",
    "    probs = result.probs  # Probs object for classification outputs\n",
    "    obb = result.obb  # Oriented boxes object for OBB outputs\n",
    "    result.show()  # display to screen\n",
    "    result.save(filename=\"result.jpg\")  # save to disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model using the following guidelines:\n",
    "- Link for various arguments: https://docs.ultralytics.com/modes/train/#train-settings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/lib/xorg-nvidia-535.113.01/lib/x86_64-linux-gnu:/usr/lib/xorg/lib/x86_64-linux-gnu:/usr/lib/xorg-nvidia-525.116.04/lib/x86_64-linux-gnu:/home/sur06423/miniconda3/envs/yolov_env/lib/python3.9/site-packages/cv2/../../lib64:\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Set library paths\n",
    "os.environ['LD_LIBRARY_PATH'] = '/usr/lib/xorg-nvidia-525.116.04/lib/x86_64-linux-gnu:' + os.environ.get('LD_LIBRARY_PATH', '')\n",
    "os.environ['LD_LIBRARY_PATH'] = '/usr/lib/xorg/lib/x86_64-linux-gnu:' + os.environ['LD_LIBRARY_PATH']\n",
    "os.environ['LD_LIBRARY_PATH'] = '/usr/lib/xorg-nvidia-535.113.01/lib/x86_64-linux-gnu:' + os.environ['LD_LIBRARY_PATH']\n",
    "\n",
    "# Verify the update\n",
    "print(os.environ['LD_LIBRARY_PATH'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.13 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.2.93 🚀 Python-3.9.19 torch-2.4.1+cu121 CUDA:0 (NVIDIA RTX A6000, 48677MiB)\n",
      "                                                           CUDA:1 (NVIDIA RTX A6000, 48677MiB)\n",
      "                                                           CUDA:2 (NVIDIA RTX A6000, 48677MiB)\n",
      "                                                           CUDA:3 (NVIDIA RTX A6000, 48677MiB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov9m.pt, data=/home/sur06423/project/Version_5_exp/Carla_Labeling-5/data.yaml, epochs=100, time=None, patience=10, batch=128, imgsz=640, save=True, save_period=1, cache=False, device=[0, 1, 2, 3], workers=6, project=/home/sur06423/project/Version_5_exp/YOLO_v9/v9_m, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=True, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/home/sur06423/project/Version_5_exp/YOLO_v9/v9_m/train\n",
      "Overriding model.yaml nc=80 with nc=4\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1    171648  ultralytics.nn.modules.block.RepNCSPELAN4    [64, 128, 128, 64, 1]         \n",
      "  3                  -1  1    276960  ultralytics.nn.modules.block.AConv           [128, 240]                    \n",
      "  4                  -1  1    629520  ultralytics.nn.modules.block.RepNCSPELAN4    [240, 240, 240, 120, 1]       \n",
      "  5                  -1  1    778320  ultralytics.nn.modules.block.AConv           [240, 360]                    \n",
      "  6                  -1  1   1414080  ultralytics.nn.modules.block.RepNCSPELAN4    [360, 360, 360, 180, 1]       \n",
      "  7                  -1  1   1556160  ultralytics.nn.modules.block.AConv           [360, 480]                    \n",
      "  8                  -1  1   2511840  ultralytics.nn.modules.block.RepNCSPELAN4    [480, 480, 480, 240, 1]       \n",
      "  9                  -1  1    577440  ultralytics.nn.modules.block.SPPELAN         [480, 480, 240]               \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1   1586880  ultralytics.nn.modules.block.RepNCSPELAN4    [840, 360, 360, 180, 1]       \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    715920  ultralytics.nn.modules.block.RepNCSPELAN4    [600, 240, 240, 120, 1]       \n",
      " 16                  -1  1    397808  ultralytics.nn.modules.block.AConv           [240, 184]                    \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1   1480320  ultralytics.nn.modules.block.RepNCSPELAN4    [544, 360, 360, 180, 1]       \n",
      " 19                  -1  1    778080  ultralytics.nn.modules.block.AConv           [360, 240]                    \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   2627040  ultralytics.nn.modules.block.RepNCSPELAN4    [720, 480, 480, 240, 1]       \n",
      " 22        [15, 18, 21]  1   4639708  ultralytics.nn.modules.head.Detect           [4, [240, 360, 480]]          \n",
      "YOLOv9m summary: 603 layers, 20,161,212 parameters, 20,161,196 gradients, 77.6 GFLOPs\n",
      "\n",
      "Transferred 124/907 items from pretrained weights\n",
      "\u001b[34m\u001b[1mDDP:\u001b[0m debug command /home/sur06423/miniconda3/envs/yolov_env/bin/python -m torch.distributed.run --nproc_per_node 4 --master_port 34159 /home/sur06423/.config/Ultralytics/DDP/_temp_c8g0t523140589315198160.py\n",
      "Ultralytics YOLOv8.2.93 🚀 Python-3.9.19 torch-2.4.1+cu121 CUDA:0 (NVIDIA RTX A6000, 48677MiB)\n",
      "                                                           CUDA:1 (NVIDIA RTX A6000, 48677MiB)\n",
      "                                                           CUDA:2 (NVIDIA RTX A6000, 48677MiB)\n",
      "                                                           CUDA:3 (NVIDIA RTX A6000, 48677MiB)\n",
      "Overriding model.yaml nc=80 with nc=4\n",
      "Transferred 901/907 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt to 'yolov8n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6.25M/6.25M [00:00<00:00, 170MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/sur06423/project/Version_5_exp/Carla_Labeling-5/train/labels.cache... 4485 images, 430 backgrounds, 0 corrupt: 100%|██████████| 4485/4485 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/sur06423/project/Version_5_exp/Carla_Labeling-5/valid/labels.cache... 1274 images, 124 backgrounds, 0 corrupt: 100%|██████████| 1274/1274 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to /home/sur06423/project/Version_5_exp/YOLO_v9/v9_m/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 149 weight(decay=0.0), 156 weight(decay=0.001), 155 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 24 dataloader workers\n",
      "Logging results to \u001b[1m/home/sur06423/project/Version_5_exp/YOLO_v9/v9_m/train\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      1/100      16.6G      1.029      2.364      1.072          5        640: 100%|██████████| 36/36 [00:19<00:00,  1.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.738      0.441      0.481      0.278\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      2/100      16.7G     0.9117     0.7436     0.9858         17        640: 100%|██████████| 36/36 [00:17<00:00,  2.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.709       0.42      0.453      0.273\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      3/100      16.5G     0.9633     0.7827      1.018         37        640: 100%|██████████| 36/36 [00:17<00:00,  2.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.446      0.357      0.267      0.141\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      4/100      16.5G      0.955     0.7687      1.022          8        640: 100%|██████████| 36/36 [00:17<00:00,  2.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.404      0.425      0.295      0.149\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      5/100      16.5G     0.9475     0.7148      1.018          6        640: 100%|██████████| 36/36 [00:17<00:00,  2.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.709      0.464      0.494      0.282\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      6/100      16.5G     0.9149     0.6489     0.9907         26        640: 100%|██████████| 36/36 [00:17<00:00,  2.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.664      0.483      0.503       0.31\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      7/100      16.7G     0.8881     0.6334     0.9825          3        640: 100%|██████████| 36/36 [00:17<00:00,  2.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.773      0.494      0.556       0.34\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      8/100      16.4G     0.8751     0.6006     0.9633         24        640: 100%|██████████| 36/36 [00:17<00:00,  2.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.787      0.488      0.556      0.341\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      9/100      16.7G     0.8369     0.5751     0.9669          1        640: 100%|██████████| 36/36 [00:17<00:00,  2.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377       0.79      0.528      0.588      0.352\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     10/100      16.5G     0.8468     0.5574     0.9529          8        640: 100%|██████████| 36/36 [00:17<00:00,  2.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.792      0.522      0.592      0.367\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     11/100      16.5G     0.8546     0.5566     0.9513         14        640: 100%|██████████| 36/36 [00:17<00:00,  2.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.781      0.533      0.594       0.36\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     12/100      16.4G     0.8409     0.5643     0.9365          1        640: 100%|██████████| 36/36 [00:17<00:00,  2.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.839      0.542      0.611      0.369\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     13/100      16.7G     0.8233     0.5271     0.9452         11        640: 100%|██████████| 36/36 [00:17<00:00,  2.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.803      0.556      0.611      0.374\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     14/100      16.5G     0.8119      0.538     0.9344         14        640: 100%|██████████| 36/36 [00:17<00:00,  2.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.841      0.546      0.629      0.392\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     15/100      16.5G     0.7984     0.5092     0.9329         24        640: 100%|██████████| 36/36 [00:17<00:00,  2.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.813      0.548       0.61      0.384\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     16/100      16.7G      0.797     0.5198     0.9386          4        640: 100%|██████████| 36/36 [00:17<00:00,  2.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.812      0.578      0.639      0.401\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     17/100      16.7G     0.8071     0.5244     0.9503         15        640: 100%|██████████| 36/36 [00:17<00:00,  2.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.821      0.572      0.639      0.396\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     18/100      16.5G      0.782     0.5131     0.9467          6        640: 100%|██████████| 36/36 [00:16<00:00,  2.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.839      0.569       0.64      0.394\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     19/100      16.7G     0.7798     0.4806     0.9288         12        640: 100%|██████████| 36/36 [00:17<00:00,  2.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.843      0.559      0.641      0.402\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     20/100      16.7G     0.7824     0.4881     0.9376         23        640: 100%|██████████| 36/36 [00:17<00:00,  2.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.812      0.585      0.655      0.419\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     21/100      16.7G     0.7584     0.4712     0.9273          4        640: 100%|██████████| 36/36 [00:17<00:00,  2.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.839      0.588      0.658       0.41\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     22/100      16.7G     0.7881     0.4912     0.9295          3        640: 100%|██████████| 36/36 [00:17<00:00,  2.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.833      0.587      0.655      0.417\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     23/100      16.7G     0.7461      0.459     0.9186         27        640: 100%|██████████| 36/36 [00:17<00:00,  2.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.836      0.587      0.663      0.428\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     24/100      16.4G     0.7402     0.4548     0.9183          3        640: 100%|██████████| 36/36 [00:17<00:00,  2.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.833      0.611      0.682      0.438\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     25/100      16.7G     0.7208     0.4559     0.9114         20        640: 100%|██████████| 36/36 [00:17<00:00,  2.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.857      0.593      0.673      0.432\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     26/100      16.7G     0.7232     0.4385     0.9269         18        640: 100%|██████████| 36/36 [00:17<00:00,  2.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.834      0.607      0.672      0.432\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     27/100      16.7G     0.7536     0.4495     0.9143         11        640: 100%|██████████| 36/36 [00:17<00:00,  2.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.844      0.601      0.677      0.426\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     28/100      16.5G     0.7188     0.4387     0.9085         20        640: 100%|██████████| 36/36 [00:17<00:00,  2.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.853      0.608      0.681       0.44\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     29/100      16.7G     0.7025     0.4222     0.8997          7        640: 100%|██████████| 36/36 [00:17<00:00,  2.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377       0.85      0.601      0.682      0.442\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     30/100      16.5G     0.7251     0.4355     0.9171         11        640: 100%|██████████| 36/36 [00:17<00:00,  2.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.841      0.611      0.682      0.435\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     31/100      16.7G     0.7015       0.43     0.9059         19        640: 100%|██████████| 36/36 [00:17<00:00,  2.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.842      0.612      0.679      0.432\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     32/100      16.7G     0.7079     0.4228     0.9017         10        640: 100%|██████████| 36/36 [00:17<00:00,  2.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.855      0.613      0.687      0.443\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     33/100      16.4G     0.6881     0.4093      0.901         13        640: 100%|██████████| 36/36 [00:17<00:00,  2.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.843      0.619      0.693      0.451\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     34/100      16.7G     0.7056     0.4234     0.9106         11        640: 100%|██████████| 36/36 [00:17<00:00,  2.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.857      0.607      0.689       0.45\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     35/100      16.7G     0.7082      0.415     0.9149         21        640: 100%|██████████| 36/36 [00:17<00:00,  2.04it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:08<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.845      0.626      0.696      0.454\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     36/100      16.7G     0.6868     0.4098     0.8993          9        640: 100%|██████████| 36/36 [00:17<00:00,  2.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.846      0.611      0.686      0.448\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     37/100      16.5G     0.6967     0.4115     0.9064         10        640: 100%|██████████| 36/36 [00:17<00:00,  2.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:08<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.876      0.625      0.707      0.465\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     38/100      16.5G     0.6614     0.4996     0.8834          0        640: 100%|██████████| 36/36 [00:17<00:00,  2.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377       0.84      0.632        0.7      0.455\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     39/100      16.7G     0.6696     0.3933      0.897         21        640: 100%|██████████| 36/36 [00:17<00:00,  2.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.839      0.629      0.697      0.451\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     40/100      16.5G     0.6763     0.4009     0.8956         15        640: 100%|██████████| 36/36 [00:17<00:00,  2.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.849      0.642      0.711      0.466\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     41/100      16.5G      0.674     0.4045     0.9049         10        640: 100%|██████████| 36/36 [00:17<00:00,  2.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.861      0.626      0.707      0.462\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     42/100      16.7G     0.6636     0.3925     0.8952         24        640: 100%|██████████| 36/36 [00:17<00:00,  2.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377       0.86      0.638       0.71      0.465\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     43/100      16.7G     0.6903     0.4305     0.9216          4        640: 100%|██████████| 36/36 [00:17<00:00,  2.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.845      0.638      0.709       0.47\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     44/100      16.5G     0.6815      0.389     0.8858         26        640: 100%|██████████| 36/36 [00:17<00:00,  2.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.864      0.641      0.714      0.469\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     45/100      16.7G     0.6495     0.3786     0.8954          8        640: 100%|██████████| 36/36 [00:17<00:00,  2.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.852      0.644      0.718      0.467\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     46/100      16.7G     0.6371     0.3702     0.8914          8        640: 100%|██████████| 36/36 [00:17<00:00,  2.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.857       0.64      0.719      0.474\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     47/100      16.5G     0.6427     0.3754     0.8886         15        640: 100%|██████████| 36/36 [00:17<00:00,  2.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.842      0.643      0.712      0.472\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     48/100      16.5G      0.654     0.3716      0.887         16        640: 100%|██████████| 36/36 [00:17<00:00,  2.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.869      0.641      0.711      0.465\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     49/100      16.5G     0.6805     0.4978     0.8718          7        640: 100%|██████████| 36/36 [00:17<00:00,  2.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.858      0.645      0.719      0.472\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     50/100      16.5G     0.6609     0.3794     0.8833         17        640: 100%|██████████| 36/36 [00:17<00:00,  2.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.864      0.645       0.72      0.476\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     51/100      16.7G     0.6499     0.3731     0.8986         10        640: 100%|██████████| 36/36 [00:17<00:00,  2.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.859      0.649      0.724      0.477\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     52/100      16.7G     0.6305     0.3617     0.8888          5        640: 100%|██████████| 36/36 [00:17<00:00,  2.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377       0.89      0.628      0.722      0.474\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     53/100      16.5G     0.6377     0.3677     0.8924          8        640: 100%|██████████| 36/36 [00:17<00:00,  2.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:08<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.856      0.645      0.722      0.477\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     54/100      16.5G     0.6111     0.3545     0.8837         14        640: 100%|██████████| 36/36 [00:17<00:00,  2.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.869      0.633      0.717      0.477\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     55/100      16.7G     0.6327     0.3755     0.8835         21        640: 100%|██████████| 36/36 [00:17<00:00,  2.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.877      0.645      0.733      0.488\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     56/100      16.7G     0.6085     0.3517     0.8862          5        640: 100%|██████████| 36/36 [00:17<00:00,  2.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.868      0.646      0.725       0.48\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     57/100      16.7G     0.6245     0.3574     0.8754         13        640: 100%|██████████| 36/36 [00:17<00:00,  2.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:08<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.827      0.665      0.725      0.479\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     58/100      16.7G     0.6184     0.3517     0.8877         21        640: 100%|██████████| 36/36 [00:17<00:00,  2.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.851      0.648      0.729      0.483\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     59/100      16.5G     0.6192     0.3456     0.8777         12        640: 100%|██████████| 36/36 [00:17<00:00,  2.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.852       0.66      0.733      0.491\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     60/100      16.5G     0.6177     0.3516     0.8796         18        640: 100%|██████████| 36/36 [00:17<00:00,  2.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.865      0.651      0.733      0.494\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     61/100      16.5G     0.6197     0.3522     0.8778         39        640: 100%|██████████| 36/36 [00:17<00:00,  2.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.873      0.651      0.739      0.492\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     62/100      16.5G     0.5986     0.3417     0.8789         33        640: 100%|██████████| 36/36 [00:17<00:00,  2.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.882      0.638      0.736      0.493\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     63/100      16.5G     0.6203     0.3509     0.8762         13        640: 100%|██████████| 36/36 [00:17<00:00,  2.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.866      0.653      0.735      0.491\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     64/100      16.6G     0.6256     0.3572     0.8717          6        640: 100%|██████████| 36/36 [00:17<00:00,  2.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.874      0.644      0.729       0.49\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     65/100      16.7G     0.6387     0.3481     0.8795          3        640: 100%|██████████| 36/36 [00:17<00:00,  2.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.897      0.636      0.739      0.499\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     66/100      16.5G     0.6141     0.3412      0.886         10        640: 100%|██████████| 36/36 [00:17<00:00,  2.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.884      0.654      0.736       0.49\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     67/100      16.7G     0.6169     0.3463     0.8807         19        640: 100%|██████████| 36/36 [00:17<00:00,  2.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.856      0.669      0.742      0.499\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     68/100      16.7G     0.5893     0.3327     0.8654         19        640: 100%|██████████| 36/36 [00:17<00:00,  2.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.883      0.651      0.739      0.494\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     69/100      16.7G     0.6141      0.339     0.8744         16        640: 100%|██████████| 36/36 [00:17<00:00,  2.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.865      0.664      0.746      0.502\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     70/100      16.5G     0.5998     0.3326     0.8734         24        640: 100%|██████████| 36/36 [00:17<00:00,  2.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.879      0.658      0.749      0.503\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     71/100      16.7G     0.5886     0.3194     0.8743         17        640: 100%|██████████| 36/36 [00:17<00:00,  2.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.858      0.659      0.739      0.502\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     72/100      16.4G     0.5867     0.3223      0.872         12        640: 100%|██████████| 36/36 [00:17<00:00,  2.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.875      0.652      0.745      0.505\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     73/100      16.5G     0.5941     0.3302      0.879         13        640: 100%|██████████| 36/36 [00:17<00:00,  2.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.867      0.662      0.741      0.499\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     74/100      16.7G      0.574     0.3189     0.8802         11        640: 100%|██████████| 36/36 [00:17<00:00,  2.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.868       0.65      0.739      0.502\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     75/100      16.7G     0.5877     0.3184     0.8699          6        640: 100%|██████████| 36/36 [00:17<00:00,  2.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.858      0.664      0.749      0.505\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     76/100      16.7G     0.5901     0.3193     0.8645          8        640: 100%|██████████| 36/36 [00:17<00:00,  2.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.869      0.657      0.745      0.502\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     77/100      16.6G     0.5871     0.3184     0.8685         22        640: 100%|██████████| 36/36 [00:17<00:00,  2.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.882      0.654      0.741      0.499\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     78/100      16.7G     0.5843     0.3114      0.881          4        640: 100%|██████████| 36/36 [00:17<00:00,  2.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.881       0.66      0.751      0.506\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     79/100      16.5G     0.5724     0.3118     0.8695         13        640: 100%|██████████| 36/36 [00:17<00:00,  2.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.881      0.664      0.755      0.513\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     80/100      16.7G     0.5643     0.3101     0.8649         36        640: 100%|██████████| 36/36 [00:17<00:00,  2.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377       0.88      0.658      0.744      0.505\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     81/100      16.7G     0.5637     0.3082     0.8695          7        640: 100%|██████████| 36/36 [00:17<00:00,  2.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.873      0.664      0.748       0.51\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     82/100      16.7G     0.5753     0.3177     0.8694          9        640: 100%|██████████| 36/36 [00:17<00:00,  2.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.879       0.66      0.746      0.506\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     83/100      16.7G     0.5701     0.3058     0.8678          8        640: 100%|██████████| 36/36 [00:17<00:00,  2.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.886      0.657      0.748      0.508\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     84/100      16.5G      0.574     0.3106     0.8676          8        640: 100%|██████████| 36/36 [00:17<00:00,  2.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.876      0.666      0.753       0.51\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     85/100      16.4G     0.5659     0.3029      0.873         11        640: 100%|██████████| 36/36 [00:17<00:00,  2.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.882      0.667      0.753      0.515\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     86/100      16.5G     0.6301     0.3754     0.9646          3        640: 100%|██████████| 36/36 [00:17<00:00,  2.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.867      0.667       0.75       0.51\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     87/100      16.5G     0.5658     0.2986     0.8649         14        640: 100%|██████████| 36/36 [00:17<00:00,  2.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.877      0.661      0.754      0.512\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     88/100      16.7G     0.5615     0.3004      0.863         16        640: 100%|██████████| 36/36 [00:17<00:00,  2.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.882      0.668      0.759      0.518\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     89/100      16.5G     0.5325     0.2825     0.8688         14        640: 100%|██████████| 36/36 [00:17<00:00,  2.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.867      0.674      0.756      0.518\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     90/100      16.7G     0.5356     0.2953     0.8738          3        640: 100%|██████████| 36/36 [00:17<00:00,  2.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.886      0.661       0.76      0.518\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     91/100      16.7G     0.6064     0.2973     0.8523         13        640: 100%|██████████| 36/36 [00:18<00:00,  2.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:08<00:00,  2.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.883      0.661      0.752      0.514\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     92/100      16.7G        0.6     0.2965     0.8516         13        640: 100%|██████████| 36/36 [00:17<00:00,  2.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.888       0.66      0.756      0.515\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     93/100      16.5G     0.5964     0.2956     0.8472          7        640: 100%|██████████| 36/36 [00:17<00:00,  2.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.882      0.664      0.752      0.514\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     94/100      16.7G     0.6065     0.2989     0.8478          6        640: 100%|██████████| 36/36 [00:17<00:00,  2.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.908      0.651      0.755      0.516\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     95/100      16.7G     0.6045     0.2971     0.8449         31        640: 100%|██████████| 36/36 [00:17<00:00,  2.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:08<00:00,  2.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.899      0.651      0.755      0.515\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     96/100      16.5G     0.5954      0.304     0.8497         13        640: 100%|██████████| 36/36 [00:17<00:00,  2.04it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:08<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.861      0.677      0.757      0.519\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     97/100      16.5G     0.5951     0.2903     0.8493         13        640: 100%|██████████| 36/36 [00:17<00:00,  2.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.859      0.676      0.759      0.521\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     98/100      16.5G     0.5931     0.2908     0.8382          3        640: 100%|██████████| 36/36 [00:17<00:00,  2.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.853      0.685      0.763      0.521\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     99/100      16.5G     0.5816     0.2836     0.8425         40        640: 100%|██████████| 36/36 [00:17<00:00,  2.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.855      0.681      0.762      0.521\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    100/100      16.6G     0.5797     0.2825     0.8511          6        640: 100%|██████████| 36/36 [00:17<00:00,  2.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:07<00:00,  2.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.859      0.681      0.761       0.52\n",
      "\n",
      "100 epochs completed in 0.933 hours.\n",
      "Optimizer stripped from /home/sur06423/project/Version_5_exp/YOLO_v9/v9_m/train/weights/last.pt, 40.8MB\n",
      "Optimizer stripped from /home/sur06423/project/Version_5_exp/YOLO_v9/v9_m/train/weights/best.pt, 40.8MB\n",
      "\n",
      "Validating /home/sur06423/project/Version_5_exp/YOLO_v9/v9_m/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.2.93 🚀 Python-3.9.19 torch-2.4.1+cu121 CUDA:0 (NVIDIA RTX A6000, 48677MiB)\n",
      "                                                           CUDA:1 (NVIDIA RTX A6000, 48677MiB)\n",
      "                                                           CUDA:2 (NVIDIA RTX A6000, 48677MiB)\n",
      "                                                           CUDA:3 (NVIDIA RTX A6000, 48677MiB)\n",
      "YOLOv9m summary (fused): 374 layers, 20,015,884 parameters, 0 gradients, 76.5 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:09<00:00,  2.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1274       7377      0.853      0.685      0.764      0.521\n",
      "            Pedestrian        333        600      0.758      0.733      0.772      0.474\n",
      "         Traffic_Signs        309        434      0.857      0.629      0.725      0.441\n",
      "               Vehicle       1034       2820      0.923      0.905      0.946       0.78\n",
      "         traffic_light        660       3523      0.876      0.472      0.612       0.39\n",
      "Speed: 0.1ms preprocess, 3.2ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1m/home/sur06423/project/Version_5_exp/YOLO_v9/v9_m/train\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Train the model: https://docs.ultralytics.com/modes/train/#train-settings\n",
    "model.train(data=\"/home/sur06423/project/Version_5_exp/Carla_Labeling-5/data.yaml\", # \tPath to the dataset configuration file (e.g., coco8.yaml). This file contains dataset-specific parameters, including paths to training and validation data, class names, and number of classes.\n",
    "            epochs=100, # Total number of training epochs. Each epoch represents a full pass over the entire dataset. Adjusting this value can affect training duration and model performance.\n",
    "            patience=10, # Number of epochs to wait without improvement in validation metrics before early stopping the training. Helps prevent overfitting by stopping training when performance plateaus.\n",
    "            batch=128, # Batch size, with three modes: set as an integer (e.g., batch=16), auto mode for 60% GPU memory utilization (batch=-1), or auto mode with specified utilization fraction (batch=0.70).\n",
    "            imgsz=640, # Target image size for training. All images are resized to this dimension before being fed into the model. Affects model accuracy and computational complexity.\n",
    "            save=True, # Enables saving of training checkpoints and final model weights. Useful for resuming training or model deployment.\n",
    "            save_period = 1, # Frequency of saving model checkpoints, specified in epochs. A value of -1 disables this feature. Useful for saving interim models during long training sessions.\n",
    "            device=[0,1,2,3], # Specifies the computational device(s) for training: a single GPU (device=0), multiple GPUs (device=0,1), CPU (device=cpu), or MPS for Apple silicon (device=mps).\n",
    "            workers=6, # Number of worker threads for data loading (per RANK if Multi-GPU training). Influences the speed of data preprocessing and feeding into the model, especially useful in multi-GPU setups.\n",
    "            project=\"/home/sur06423/project/Version_5_exp/YOLO_v9/v9_m\", # Name of the project directory where training outputs are saved. Allows for organized storage of different experiments.\n",
    "            pretrained = True, # Determines whether to start training from a pretrained model. Can be a boolean value or a string path to a specific model from which to load weights. Enhances training efficiency and model performance.\n",
    "            optimizer = \"auto\", # Choice of optimizer for training. Options include SGD, Adam, AdamW, NAdam, RAdam, RMSProp etc., or auto for automatic selection based on model configuration. Affects convergence speed and stability.\n",
    "            verbose = True, # Enables verbose output during training, providing detailed logs and progress updates. Useful for debugging and closely monitoring the training process.\n",
    "            seed = 0, # Sets the random seed for training, ensuring reproducibility of results across runs with the same configurations.\n",
    "            amp = True, # Enables Automatic Mixed Precision (AMP) training, reducing memory usage and possibly speeding up training with minimal impact on accuracy.\n",
    "            profile =True, # Enables profiling of ONNX and TensorRT speeds during training, useful for optimizing model deployment.\n",
    "            val=True, # Enables validation during training, allowing for periodic evaluation of model performance on a separate dataset.\n",
    "            plots = True, #Generates and saves plots of training and validation metrics, as well as prediction examples, providing visual insights into model performance and learning progression.                \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results on Validation set:\n",
    "100 epochs completed in 0.933 hours.\n",
    "Optimizer stripped from /home/sur06423/project/Version_5_exp/YOLO_v9/v9_m/train/weights/last.pt, 40.8MB\n",
    "Optimizer stripped from /home/sur06423/project/Version_5_exp/YOLO_v9/v9_m/train/weights/best.pt, 40.8MB\n",
    "\n",
    "Validating /home/sur06423/project/Version_5_exp/YOLO_v9/v9_m/train/weights/best.pt...\n",
    "Ultralytics YOLOv8.2.93 🚀 Python-3.9.19 torch-2.4.1+cu121 CUDA:0 (NVIDIA RTX A6000, 48677MiB)\n",
    "                                                           CUDA:1 (NVIDIA RTX A6000, 48677MiB)\n",
    "                                                           CUDA:2 (NVIDIA RTX A6000, 48677MiB)\n",
    "                                                           CUDA:3 (NVIDIA RTX A6000, 48677MiB)\n",
    "YOLOv9m summary (fused): 374 layers, 20,015,884 parameters, 0 gradients, 76.5 GFLOPs\n",
    "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 20/20 [00:09<00:00,  2.07it/s]\n",
    "                   all       1274       7377      0.853      0.685      0.764      0.521\n",
    "            Pedestrian        333        600      0.758      0.733      0.772      0.474\n",
    "         Traffic_Signs        309        434      0.857      0.629      0.725      0.441\n",
    "               Vehicle       1034       2820      0.923      0.905      0.946       0.78\n",
    "         traffic_light        660       3523      0.876      0.472      0.612       0.39\n",
    "Speed: 0.1ms preprocess, 3.2ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
    "Results saved to /home/sur06423/project/Version_5_exp/YOLO_v9/v9_m/train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the results on Test dataset\n",
    "- The above results was on the validation set of the Carla_labeling-v5 dataset (See the Image counts)\n",
    "- Now we need to calculate the metrics on the test set of the Carla_labeling-v5 dataset containing only 641 images.\n",
    "- Below is the script to do so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.93 🚀 Python-3.9.19 torch-2.4.1+cu121 CUDA:0 (NVIDIA RTX A6000, 48677MiB)\n",
      "YOLOv9m summary (fused): 374 layers, 20,015,884 parameters, 0 gradients, 76.5 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/sur06423/project/Version_5_exp/Carla_Labeling-5/test/labels.cache... 641 images, 53 backgrounds, 0 corrupt: 100%|██████████| 641/641 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:12<00:00,  2.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        641       3701      0.896      0.649      0.795      0.586\n",
      "            Pedestrian        182        332      0.796      0.657      0.775      0.526\n",
      "         Traffic_Signs        168        230      0.947      0.617      0.791      0.538\n",
      "               Vehicle        528       1377      0.947      0.882      0.935       0.81\n",
      "         traffic_light        338       1762      0.895       0.44      0.679      0.471\n",
      "Speed: 0.4ms preprocess, 5.9ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Saving runs/detect/val/predictions.json...\n",
      "Results saved to \u001b[1mruns/detect/val\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load YOLOv10s model from scratch\n",
    "# model = YOLO(\"yolov10s.pt\")\n",
    "# Load YOLOv10s Best weights on carla dataset\n",
    "model = YOLO(\"/home/sur06423/project/Version_5_exp/YOLO_v9/v9_m/train/weights/last.pt\")\n",
    "\n",
    "# Train the model: https://docs.ultralytics.com/modes/train/#train-settings\n",
    "validation_results = model.val(data=\"/home/sur06423/project/Version_5_exp/Carla_Labeling-5/data.yaml\", \n",
    "            batch=128, \n",
    "            imgsz=640,\n",
    "            save_json = True, # If True, saves the results to a JSON file for further analysis or integration with other tools.\n",
    "            conf=0.25, # Sets the minimum confidence threshold for detections. Detections with confidence below this threshold are discarded.\n",
    "            iou=0.6, # Sets the Intersection Over Union (IoU) threshold for Non-Maximum Suppression (NMS). Helps in reducing duplicate detections.\n",
    "            device=0, \n",
    "            split=\"test\",              \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results on Last checpoint (100th epoch):\n",
    "Ultralytics YOLOv8.2.93 🚀 Python-3.9.19 torch-2.4.1+cu121 CUDA:0 (NVIDIA RTX A6000, 48677MiB)\n",
    "YOLOv9m summary (fused): 374 layers, 20,015,884 parameters, 0 gradients, 76.5 GFLOPs\n",
    "val: Scanning /home/sur06423/project/Version_5_exp/Carla_Labeling-5/test/labels.cache... 641 images, 53 backgrounds, 0 corrupt: 100%|██████████| 641/641 [00:00<?, ?it/s]\n",
    "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:12<00:00,  2.00s/it]\n",
    "                   all        641       3701      0.896      0.649      0.795      0.586\n",
    "            Pedestrian        182        332      0.796      0.657      0.775      0.526\n",
    "         Traffic_Signs        168        230      0.947      0.617      0.791      0.538\n",
    "               Vehicle        528       1377      0.947      0.882      0.935       0.81\n",
    "         traffic_light        338       1762      0.895       0.44      0.679      0.471\n",
    "Speed: 0.4ms preprocess, 5.9ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
    "Saving runs/detect/val/predictions.json...\n",
    "Results saved to runs/detect/val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results on Test Set using Best Checkpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.93 🚀 Python-3.9.19 torch-2.4.1+cu121 CUDA:0 (NVIDIA RTX A6000, 48677MiB)\n",
      "YOLOv9m summary (fused): 374 layers, 20,015,884 parameters, 0 gradients, 76.5 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/sur06423/project/Version_5_exp/Carla_Labeling-5/test/labels.cache... 641 images, 53 backgrounds, 0 corrupt: 100%|██████████| 641/641 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:11<00:00,  1.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        641       3701      0.897      0.648      0.795      0.586\n",
      "            Pedestrian        182        332      0.815      0.663      0.781      0.532\n",
      "         Traffic_Signs        168        230      0.933      0.609      0.785      0.534\n",
      "               Vehicle        528       1377      0.946      0.885      0.937       0.81\n",
      "         traffic_light        338       1762      0.894      0.436      0.678      0.468\n",
      "Speed: 0.3ms preprocess, 5.2ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "Saving runs/detect/val2/predictions.json...\n",
      "Results saved to \u001b[1mruns/detect/val2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load YOLOv10s model from scratch\n",
    "# model = YOLO(\"yolov10s.pt\")\n",
    "# Load the model\n",
    "model = YOLO(\"/home/sur06423/project/Version_5_exp/YOLO_v9/v9_m/train/weights/best.pt\")\n",
    "\n",
    "# Train the model: https://docs.ultralytics.com/modes/train/#train-settings\n",
    "validation_results = model.val(data=\"/home/sur06423/project/Version_5_exp/Carla_Labeling-5/data.yaml\", \n",
    "            batch=128, \n",
    "            imgsz=640,\n",
    "            save_json = True, # If True, saves the results to a JSON file for further analysis or integration with other tools.\n",
    "            conf=0.25, # Sets the minimum confidence threshold for detections. Detections with confidence below this threshold are discarded.\n",
    "            iou=0.6, # Sets the Intersection Over Union (IoU) threshold for Non-Maximum Suppression (NMS). Helps in reducing duplicate detections.\n",
    "            device=0, \n",
    "            split=\"test\",              \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taking the Optimal value from the F1-Confidence curve for Optimal Confidence\n",
    "- Optimal Confidence YOLOv9m - 0.156\n",
    "- IoU threshold : 0.5\n",
    "- Results save d at: runs/detect/val3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ Python>=3.10 is required, but Python==3.9.19 is currently installed \n",
      "Ultralytics 8.3.13 🚀 Python-3.9.19 torch-2.4.1+cu121 CUDA:0 (NVIDIA RTX A6000, 48677MiB)\n",
      "YOLOv9m summary (fused): 374 layers, 20,015,884 parameters, 0 gradients, 76.5 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/sur06423/project/Version_5_exp/Carla_Labeling-5/test/labels.cache... 641 images, 53 backgrounds, 0 corrupt: 100%|██████████| 641/641 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:09<00:00,  1.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        641       3701      0.859       0.68      0.802      0.582\n",
      "            Pedestrian        182        332      0.753       0.69      0.781      0.521\n",
      "         Traffic_Signs        168        230       0.89       0.67      0.805      0.532\n",
      "               Vehicle        528       1377      0.933      0.893       0.94       0.81\n",
      "         traffic_light        338       1762      0.861      0.466      0.682      0.464\n",
      "Speed: 2.0ms preprocess, 5.6ms inference, 0.0ms loss, 1.7ms postprocess per image\n",
      "Saving runs/detect/val3/predictions.json...\n",
      "Results saved to \u001b[1mruns/detect/val3\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load YOLOv10s model from scratch\n",
    "# model = YOLO(\"yolov10s.pt\")\n",
    "# Load YOLOv10s Best weights on carla dataset\n",
    "model = YOLO(\"/home/sur06423/project/Version_5_exp/YOLO_v9/v9_m/train/weights/last.pt\")\n",
    "\n",
    "# Train the model: https://docs.ultralytics.com/modes/train/#train-settings\n",
    "validation_results = model.val(data=\"/home/sur06423/project/Version_5_exp/Carla_Labeling-5/data.yaml\", \n",
    "            batch=128, \n",
    "            imgsz=640,\n",
    "            save_json = True, # If True, saves the results to a JSON file for further analysis or integration with other tools.\n",
    "            conf=0.156, # Sets the minimum confidence threshold for detections. Detections with confidence below this threshold are discarded.\n",
    "            iou=0.5, # Sets the Intersection Over Union (IoU) threshold for Non-Maximum Suppression (NMS). Helps in reducing duplicate detections.\n",
    "            device=0, \n",
    "            split=\"test\",              \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best + Taking the Optimal value from the F1-Confidence curve for Optimal Confidence\n",
    "- Optimal Confidence YOLOv9m - 0.156\n",
    "- IoU threshold : 0.5\n",
    "- Results save d at: runs/detect/val4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ Python>=3.10 is required, but Python==3.9.19 is currently installed \n",
      "Ultralytics 8.3.13 🚀 Python-3.9.19 torch-2.4.1+cu121 CUDA:0 (NVIDIA RTX A6000, 48677MiB)\n",
      "YOLOv9m summary (fused): 374 layers, 20,015,884 parameters, 0 gradients, 76.5 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/sur06423/project/Version_5_exp/Carla_Labeling-5/test/labels.cache... 641 images, 53 backgrounds, 0 corrupt: 100%|██████████| 641/641 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:08<00:00,  1.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        641       3701      0.859      0.674        0.8      0.581\n",
      "            Pedestrian        182        332      0.763      0.687      0.783      0.523\n",
      "         Traffic_Signs        168        230      0.877      0.652      0.794      0.527\n",
      "               Vehicle        528       1377      0.932      0.893       0.94       0.81\n",
      "         traffic_light        338       1762      0.865      0.465      0.682      0.464\n",
      "Speed: 1.8ms preprocess, 5.7ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "Saving runs/detect/val4/predictions.json...\n",
      "Results saved to \u001b[1mruns/detect/val4\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load YOLOv10s model from scratch\n",
    "# model = YOLO(\"yolov10s.pt\")\n",
    "# Load YOLOv10s Best weights on carla dataset\n",
    "model = YOLO(\"/home/sur06423/project/Version_5_exp/YOLO_v9/v9_m/train/weights/best.pt\")\n",
    "\n",
    "# Train the model: https://docs.ultralytics.com/modes/train/#train-settings\n",
    "validation_results = model.val(data=\"/home/sur06423/project/Version_5_exp/Carla_Labeling-5/data.yaml\", \n",
    "            batch=128, \n",
    "            imgsz=640,\n",
    "            save_json = True, # If True, saves the results to a JSON file for further analysis or integration with other tools.\n",
    "            conf=0.156, # Sets the minimum confidence threshold for detections. Detections with confidence below this threshold are discarded.\n",
    "            iou=0.5, # Sets the Intersection Over Union (IoU) threshold for Non-Maximum Suppression (NMS). Helps in reducing duplicate detections.\n",
    "            device=0, \n",
    "            split=\"test\",              \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Epoch 98 +  Optimal Confidence + IoU = 0.6\n",
    "- Optimal Confidence YOLOv9m - 0.156\n",
    "- IoU threshold : 0.6\n",
    "- Results save d at: runs/detect/val5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ Python>=3.10 is required, but Python==3.9.19 is currently installed \n",
      "Ultralytics 8.3.13 🚀 Python-3.9.19 torch-2.4.1+cu121 CUDA:0 (NVIDIA RTX A6000, 48677MiB)\n",
      "YOLOv9m summary (fused): 374 layers, 20,015,884 parameters, 0 gradients, 76.5 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/sur06423/project/Version_5_exp/Carla_Labeling-5/test/labels.cache... 641 images, 53 backgrounds, 0 corrupt: 100%|██████████| 641/641 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:08<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        641       3701      0.853      0.674      0.799       0.58\n",
      "            Pedestrian        182        332       0.75      0.687       0.78      0.522\n",
      "         Traffic_Signs        168        230      0.877      0.652      0.794      0.527\n",
      "               Vehicle        528       1377      0.923      0.894       0.94      0.809\n",
      "         traffic_light        338       1762      0.862      0.465      0.681      0.463\n",
      "Speed: 1.9ms preprocess, 5.7ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
      "Saving runs/detect/val5/predictions.json...\n",
      "Results saved to \u001b[1mruns/detect/val5\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load YOLOv10s model from scratch\n",
    "# model = YOLO(\"yolov10s.pt\")\n",
    "# Load YOLOv10s Best weights on carla dataset\n",
    "model = YOLO(\"/home/sur06423/project/Version_5_exp/YOLO_v9/v9_m/train/weights/best.pt\")\n",
    "\n",
    "# Train the model: https://docs.ultralytics.com/modes/train/#train-settings\n",
    "validation_results = model.val(data=\"/home/sur06423/project/Version_5_exp/Carla_Labeling-5/data.yaml\", \n",
    "            batch=128, \n",
    "            imgsz=640,\n",
    "            save_json = True, # If True, saves the results to a JSON file for further analysis or integration with other tools.\n",
    "            conf=0.156, # Sets the minimum confidence threshold for detections. Detections with confidence below this threshold are discarded.\n",
    "            iou=0.6, # Sets the Intersection Over Union (IoU) threshold for Non-Maximum Suppression (NMS). Helps in reducing duplicate detections.\n",
    "            device=0, \n",
    "            split=\"test\",              \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seperate evaluation on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ Python>=3.10 is required, but Python==3.9.19 is currently installed \n",
      "Ultralytics 8.3.13 🚀 Python-3.9.19 torch-2.4.1+cu121 CUDA:0 (NVIDIA RTX A6000, 48677MiB)\n",
      "YOLOv9m summary (fused): 374 layers, 20,015,884 parameters, 0 gradients, 76.5 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/sur06423/project/Version_5_exp/Carla_Labeling-5/train/labels.cache... 4485 images, 430 backgrounds, 0 corrupt: 100%|██████████| 4485/4485 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 36/36 [00:41<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4485      26788      0.927      0.694       0.83      0.653\n",
      "            Pedestrian       1229       2227      0.888      0.754      0.856       0.65\n",
      "         Traffic_Signs       1093       1459      0.929      0.668      0.817      0.589\n",
      "               Vehicle       3636      10031      0.964      0.915      0.954      0.854\n",
      "         traffic_light       2373      13071      0.929      0.438      0.693      0.518\n",
      "Speed: 0.4ms preprocess, 5.2ms inference, 0.0ms loss, 0.6ms postprocess per image\n",
      "Saving runs/detect/val6/predictions.json...\n",
      "Results saved to \u001b[1mruns/detect/val6\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load your model\n",
    "model = YOLO('/home/sur06423/project/Version_5_exp/YOLO_v9/v9_m/train/weights/best.pt')  # replace with your model path\n",
    "\n",
    "# Validate on custom dataset\n",
    "results = model.val(data='/home/sur06423/project/Version_5_exp/Carla_Labeling-5/data.yaml',\n",
    "            batch=128, \n",
    "            imgsz=640,\n",
    "            save_json = True, # If True, saves the results to a JSON file for further analysis or integration with other tools.\n",
    "            conf=0.25, # Sets the optimal confidence threshold for detections. Detections with confidence below this threshold are discarded.\n",
    "            iou=0.6, # Sets the Intersection Over Union (IoU) threshold for Non-Maximum Suppression (NMS). Helps in reducing duplicate detections.\n",
    "            device=0, \n",
    "            split=\"train\", \n",
    ")  # Ensure your YAML points to your desired dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook is complete.\n",
    "- All the cell are executed and saved for later use.\n",
    "- Results are saved in the corresponding directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
